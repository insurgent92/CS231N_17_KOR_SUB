0
00:00:00,000 --> 00:00:06,000
Translated by visionNoob, KNU
https://github.com/insurgent92/CS231N_17_KOR_SUB

1
00:00:06,971 --> 00:00:10,106
CS231n 두번째 시간에 오신걸 환영합니다.

2
00:00:10,106 --> 00:00:12,646
화요일에 했던 것을 되짚어보자면

3
00:00:12,646 --> 00:00:15,098
컴퓨터비전이 무엇인지,

4
00:00:15,098 --> 00:00:16,187
역사는 어떠했는지,

5
00:00:16,187 --> 00:00:18,101
그리고 이 수업에 대해 다뤘었습니다.

6
00:00:18,101 --> 00:00:21,451
그리고 오늘은 본격적으로 수업을
진행하는 첫 날입니다.

7
00:00:21,451 --> 00:00:23,339
그리고 실생활에서

8
00:00:23,339 --> 00:00:27,864
우리가 배울 알고리즘이 정확히 어떻게
적용되는지를 아주 깊게 살펴 볼 것입니다.

9
00:00:27,864 --> 00:00:31,927
강의의 처음에는 큰 흐름을 다룰 것이고,

10
00:00:31,927 --> 00:00:35,574
그리고 대부분의 수업에서는 좀 더 깊은 
내용을 다룰 것이며

11
00:00:35,574 --> 00:00:39,617
다양한 알고리즘들의 
세부적인 매커니즘에 초점을 맞출 것입니다.

12
00:00:39,617 --> 00:00:43,419
오늘은 이제 첫 학습 알고리즘을 살펴볼 것인데요,
아마 재밌을 것입니다, 제 생각에는요.

13
00:00:43,419 --> 00:00:47,535
일단 진행에 앞서 몇가지 공지사항을 알려드리겠습니다.

14
00:00:47,535 --> 00:00:48,785
첫 번째는 Piazza에 관한 것인데요

15
00:00:49,645 --> 00:00:51,580
어제 확인했을때

16
00:00:51,580 --> 00:00:55,357
Piazza를 가입한 인원이 500명쯤
되었던 것으로 기억합니다.

17
00:00:55,357 --> 00:00:58,493
그리고 그것은 100여명 가량이
아직 가입을 하지 않았다는 것이지요

18
00:00:58,493 --> 00:01:01,457
저는 Piazza가 학생과 조교들의

19
00:01:01,457 --> 00:01:04,221
주요 의사소통 수단이 되었으면 좋겠습니다.

20
00:01:04,221 --> 00:01:07,401
프로젝트 아이디어나, 중간고사, 컨퍼런스와 관련된 질문이

21
00:01:07,401 --> 00:01:12,841
조교들의 메일로 너무 많이 오고 있습니다.

22
00:01:12,841 --> 00:01:16,138
그리고 이런 종류의 질문은 Piazza에서
이루어져야만 합니다.

23
00:01:16,138 --> 00:01:21,568
모든 조교들이 Piazza를  수시로 확인하고 있기 때문에, 
Piazza로 질문을 하는것이 훨씬 더 빠를 것입니다.

24
00:01:21,568 --> 00:01:26,234
이메일로 보내면 여러 메일 리스트랑 섞여서
답장을 못 할 수도 있습니다.

25
00:01:26,234 --> 00:01:28,983
또한 SCPD 학생들 중 일부는

26
00:01:28,983 --> 00:01:33,629
Piazza 가입에 어려움을 겪고 있습니다.

27
00:01:33,629 --> 00:01:37,791
SCPD 학생들은 @ stanford.edu 이메일을
부여 받아야 합니다.

28
00:01:38,804 --> 00:01:40,733
이메일 주소를 부여받으면

29
00:01:40,733 --> 00:01:44,276
그때 Stanford 이메일로 Piazaa에
가입할 수 있습니다.

30
00:01:44,276 --> 00:01:46,908
아마 이 문제는 지금 여기 앉아있는 분들은
상관 없겠지만

31
00:01:46,908 --> 00:01:50,408
SCPD로 듣고있는 학생들에게 말씀드리는 것입니다.

32
00:01:52,191 --> 00:01:55,643
다음 사항은 바로 과제에 관한 것입니다.

33
00:01:55,643 --> 00:01:58,178
과제 1이 오늘 늦게 업로드 될 것입니다.

34
00:01:58,178 --> 00:01:59,517
아마 오후가 될 것 같습니다만

35
00:01:59,517 --> 00:02:03,043
오늘 자기전에는 꼭 과제가 올라갈 것임을
약속드립니다.

36
00:02:03,043 --> 00:02:04,589
하지만 여러분이 조금 불안하고

37
00:02:04,589 --> 00:02:07,304
지금 당장 과제를 하고싶다면

38
00:02:07,304 --> 00:02:10,531
과제 1의 작년버전을 찾을 수 있을 것입니다.

39
00:02:10,531 --> 00:02:12,684
작년 버전도 거의 똑같습니다.

40
00:02:12,684 --> 00:02:15,081
단지 아주 조금만 손 보고 있습니다.

41
00:02:15,081 --> 00:02:19,082
예를 들어 Python 2.7버전에서 
Python3으로 업그레이드하는것 등이죠

42
00:02:19,082 --> 00:02:20,943
그리고 아주 작은 외관의 변화가 있고

43
00:02:20,943 --> 00:02:24,742
내용만 보면 작년과 같습니다.

44
00:02:24,742 --> 00:02:28,665
이번 과제에서 여러분은 여러분만의  k-NN을 
구현하게 될 것인데요

45
00:02:28,665 --> 00:02:30,686
우리가 이번 강의에서 다룰 것입니다.

46
00:02:30,686 --> 00:02:33,514
여러분은 또한 몇가지 선형 분류기를 구현할 것인데

47
00:02:33,514 --> 00:02:35,694
SVM과 Softmax 뿐만 아니라

48
00:02:35,694 --> 00:02:37,927
2-layer 신경망도 구현할 것입니다.

49
00:02:37,927 --> 00:02:42,160
그리고 앞으로 몇 강의동안
그 내용을 모두 다룰 것입니다.

50
00:02:43,112 --> 00:02:46,168
그리고 모든 과제는 Python과 
Numpy를 사용하고 있습니다.

51
00:02:46,168 --> 00:02:49,229
Python이나 Numpy에 익숙하지 않다면

52
00:02:49,229 --> 00:02:51,608
관련한 tutorial이 있으며, 여러분은

53
00:02:51,608 --> 00:02:54,312
우리 강의 사이트에서 찾아 볼 수 있습니다.

54
00:02:54,312 --> 00:02:56,856
그리고 이것은 사실 엄청나게 중요합니다.

55
00:02:56,856 --> 00:02:59,211
NumPy는 여러분들이 vectorized 연산을 아주
효율적으로 할 수 있게 해줄 것이며

56
00:02:59,211 --> 00:03:03,856
방대한 양의 계산은 단지 코드 몇 줄로
가능하도록 해 줄 것입니다.

57
00:03:03,856 --> 00:03:06,081
이건 완전 중요한데, 왜냐하면

58
00:03:06,081 --> 00:03:10,288
대부분의 수치계산, 기계학습과 같은 것들이

59
00:03:10,288 --> 00:03:13,424
vectorized 연산을 수행하기 때문입니다.

60
00:03:13,424 --> 00:03:16,964
그리고 여러분들은 첫 과제를 하면서
많은 연습을 할 수 있을 것입니다.

61
00:03:16,964 --> 00:03:23,449
그러니 Matlab, Numpy와 같은 vectorized 
tensor 계산이 익숙하지 않은 분들은

62
00:03:23,449 --> 00:03:27,606
일찌감치 과제를 시작하기를 추천드립니다.

63
00:03:27,606 --> 00:03:32,175
그리고 tutorial도 아주 주의깊에 읽어보시기 바랍니다.

64
00:03:32,175 --> 00:03:40,198
또 한가지 알려드릴 것은 이 수업에서 쓸
Google Cloud가 공직적으로 지원 된다는 것입니다.

65
00:03:40,198 --> 00:03:43,630
Google Cloud는 Amazon AWS와 유사합니다

66
00:03:43,630 --> 00:03:46,694
여러분은 cloud에서 가상 머신을
사용할 수 있습니다.

67
00:03:46,694 --> 00:03:50,432
이런 가상 머신은 GPU들을 지닐 수 있습니다.

68
00:03:50,432 --> 00:03:55,386
현재 Googld Cloud 사용법과 이것으로 과제를 하는
방법에 관한 Tutorial을 작성중입니다.

69
00:03:55,386 --> 00:04:04,723
여러분들이 이미지만 다운받으면 Google Cloud를 통해
과제를 차질없이 진행할 수 있도록 하기 위함입니다.

70
00:04:04,723 --> 00:04:08,437
그리고 google에서 우리 수업을
아주 잘 지원하고 있기 때문에

71
00:04:08,437 --> 00:04:15,582
Google Cloud Credits을 무료로 쓸 수 있는 쿠폰을
여러분들에게 나누어 줄 수 있을 것입니다.

72
00:04:15,582 --> 00:04:24,015
여러분들은 자유롭게 과제나 프로젝트를 수행할때 필요한
GPU나 고사양 컴퓨터와 같은 자원들을 사용할 수 있습니다.

73
00:04:24,015 --> 00:04:28,023
아마도 오늘  Piazza에 자세한 사항을
포스팅 하도록 하겠습니다.

74
00:04:28,023 --> 00:04:29,300
여러분들에게 말씀드리고 싶었던 것은 ,

75
00:04:29,300 --> 00:04:35,566
본인의 Laptop을 사용해도 되는지와 같은 여러 질문을 받았습니다만

76
00:04:35,566 --> 00:04:41,774
제 답변은, 여러분은 Google Cloud를 사용할 수 있다는 것이고
이를 위해 쿠폰을 제공받을 것입니다.

77
00:04:43,923 --> 00:04:44,756
자 그럼

78
00:04:45,959 --> 00:04:49,716
지금까지 몇가지 공지사항을
전달해 드렸고,

79
00:04:49,716 --> 00:04:53,681
그런 다음 내용을 자세히 살펴 봅니다.

80
00:04:53,681 --> 00:04:58,125
저번 강의에서 Image Classification에 대해
조금 말씀드렸습니다

81
00:04:58,125 --> 00:05:00,450
이것은 컴퓨터비전의 핵심 과제입니다.

82
00:05:00,450 --> 00:05:04,048
그리고 우리가 가장 가장 초점을 맞출 것입니다.

83
00:05:04,048 --> 00:05:04,964
정확히,

84
00:05:04,964 --> 00:05:07,832
Image Classification을 어떻게 할 수 있을까요?

85
00:05:07,832 --> 00:05:09,750
그래서 좀더 구체적으로,

86
00:05:09,750 --> 00:05:12,142
여러분이 Image Classification을 할때

87
00:05:12,142 --> 00:05:14,259
여러분은 입력 이미지를 받습니다.

88
00:05:14,259 --> 00:05:16,457
여기 예제에 귀여운 고양이가 있습니다.

89
00:05:16,457 --> 00:05:22,455
그리고 시스템은 미리 정해놓은 
카테고리를 알고 있습니다.

90
00:05:22,455 --> 00:05:29,134
그런 카테고리는 개나 고양이 트럭, 비행기 같을 것일 수 있으며

91
00:05:29,134 --> 00:05:34,831
컴퓨터가 할 일은 사진을 보고 
그중 하나를 고르는 것입니다.

92
00:05:34,831 --> 00:05:36,444
이건 엄청 쉬워보입니다.

93
00:05:36,444 --> 00:05:44,346
왜냐면 여러분의 뇌에 있는 시각 체계는 이런 류의 
시간 인식 작업에 고도화 되어 있기 때문입니다.

94
00:05:44,346 --> 00:05:48,232
하지만 기계한테는 정말 어려운 일입니다.

95
00:05:48,232 --> 00:05:53,236
컴퓨터가 이 이미지를 볼때 무엇을 보고 있는지에 대해서
좀만 더 깊게 생각해 본다면

96
00:05:53,236 --> 00:05:57,428
컴퓨터는 우리와는 다르게 고양이 라는 생각을
하지 못 할 것입니다.

97
00:05:57,428 --> 00:06:01,755
컴퓨터는 이미지를 아주 큰 격자 모양의 숫자집합으로
표현하고 있습니다.

98
00:06:01,755 --> 00:06:05,922
800x600 이미지 같이 말입니다.

99
00:06:07,371 --> 00:06:13,176
그리고 각 픽셀은 숫자 세개로 표현되는데 
red, green, blue 값을 의미합니다.

100
00:06:13,176 --> 00:06:15,769
다시 말하자면, 컴퓨터한테 이미지는
단지 거대한 숫자 집합에 불과합니다.

101
00:06:15,769 --> 00:06:24,841
이 숫자 거대한  집합에서 고양이 라는 개념을 끄집어 
내는 것은 정말로 힘듭니다.

102
00:06:26,956 --> 00:06:30,186
그래서 우리는 이걸 의미적론적인 차이라고 부릅니다.

103
00:06:30,186 --> 00:06:32,735
이게 고양이다 라는 생각 혹은 
고양이 라는 레이블은

104
00:06:32,735 --> 00:06:35,462
우리가 이 이미지에 붙인 의미상의 레이블입니다.

105
00:06:35,462 --> 00:06:42,897
그리고 이 이미지가 "고양이다" 라는 것과 실제 컴퓨터가
보는 픽셀 값과는 아주 큰 차이가 있습니다.

106
00:06:42,897 --> 00:06:45,503
이건 정말 어려운 문제인데 왜냐하면

107
00:06:45,503 --> 00:06:48,901
여러분이 이 사진에 아주 미묘한 변화만 주더라도

108
00:06:48,901 --> 00:06:51,916
저 픽셀 값들은 모조리 다 바뀌게 될 것입니다.

109
00:06:51,916 --> 00:06:54,038
예를들어 저 고양이와 똑같은 고양이를 데리고,

110
00:06:54,038 --> 00:06:55,622
그리고 고양이가 계속 앉아있고,

111
00:06:55,622 --> 00:06:57,352
심지어 조금의 미동도 하지 않는다면

112
00:06:57,352 --> 00:06:58,782
아무 일도 일어나진 않을 것입니다.

113
00:06:58,782 --> 00:07:06,921
하지만 우리가 카메라를 조금만 옆으로 옮긴다면 모든 픽셀
하나 하나가 전부 달라질 것입니다.

114
00:07:06,921 --> 00:07:09,431
하지만 여전히 달라진 픽셀 값도
고양이를 표현하고 있는 것이죠

115
00:07:09,431 --> 00:07:12,754
우리의 알고리즘은 이런 것들에
강인해야 합니다.

116
00:07:12,754 --> 00:07:16,260
바라보는 방향 뿐만 아니라
또다는 문제는 바로 조명입니다.

117
00:07:16,260 --> 00:07:19,298
장면에 따라 서로 다른 조명 조건이 있을 수 있습니다.

118
00:07:19,298 --> 00:07:22,500
고양이가 엄청 어두운 곳에 있던

119
00:07:22,500 --> 00:07:25,520
밝은 곳에 있던, 고양이는 여전히 고양이입니다

120
00:07:25,520 --> 00:07:28,488
우리 알고리즘은 이것에 강인해야 합니다.

121
00:07:28,488 --> 00:07:30,145
객체는 또한 변형될 수 있습니다.

122
00:07:30,145 --> 00:07:34,549
제 생각엔 저기 보이는 것 처럼 
고양이가 제일 많이 변형이 가능한 것 같습니다.

123
00:07:34,549 --> 00:07:38,940
고양이들은 다양한 자세를 취할 수 있습니다.

124
00:07:38,940 --> 00:07:42,441
그리고 우리의 알고리즘은 이런 다양한 종류의
변형에도 강인해야 합니다.

125
00:07:43,442 --> 00:07:45,823
가려짐(occlusion)에서의 문제도 있습니다.

126
00:07:45,823 --> 00:07:49,762
여러분은 고양이의 일부만 볼 수 있을수도 있습니다.
예컨데

127
00:07:49,762 --> 00:07:53,686
고양이의 얼굴 만이라던가, 극단적으로는 소파 쿠션에 숨은
고양이의 꼬리만 볼 수도 있습니다.

128
00:07:53,686 --> 00:07:58,897
사람은 이게 고양이다 라는 것을
아주 쉽게 알 수 있습니다

129
00:07:58,897 --> 00:08:01,532
여전히 이것이 고양이 이미지라는 것을 인식하고 있습니다.

130
00:08:01,532 --> 00:08:08,460
우리의 알고리즘도 이것에 강인해 져야 합니다.
제 생각엔 아주 어려운 문제일 것 같긴 하지만요

131
00:08:08,460 --> 00:08:10,792
 background clutter라는 문제도 있습니다.
(배경과 비슷한 경우)

132
00:08:10,792 --> 00:08:16,677
전경 객체인 고양이가 배경과 완전히
비슷하게 생겼을 수도 있습니다.

133
00:08:16,677 --> 00:08:20,389
이것 또한 우리가 처리해야 할 또 다른
과제 중 하나입니다.

134
00:08:20,389 --> 00:08:23,637
또한 클래스 내부에서의 다양성과
관련된 문제도 있습니다.

135
00:08:23,637 --> 00:08:28,455
고양이라는 한 개념이 고양이의 다양한 모습들을 전부 
소화해 내야 합니다.

136
00:08:28,455 --> 00:08:32,158
고양이들은 다양한 외형과 크기, 색, 나이를 지니고 있습니다.

137
00:08:32,158 --> 00:08:36,345
우리의 알고리즘은 그러한 다양한 변화도 
다룰 수 있어야 합니다.

138
00:08:36,345 --> 00:08:40,033
이것 사실 엄청나게 어려운 문제입니다.

139
00:08:40,033 --> 00:08:47,931
우리 뇌는 이런 것들을 아주 잘 해내기 때문에, 컴퓨터에게는 
이 작업이 얼마나 어려울지를 까먹을 수도 있습니다.

140
00:08:47,931 --> 00:08:54,288
그러나 만약 우리가 위에서 언급한 모든 문제를 다룰 수
있는 프로그램을 원한다면, 그리고 단연 고양이 뿐만 아니라

141
00:08:54,288 --> 00:08:59,052
우리가 상상할 수 있는 어떤 객체에 대해서도 다룰 수 있는
프로그램이여야 한다면, 이것은 판타스틱하게 어려운 문제입니다.

142
00:08:59,052 --> 00:09:03,078
저 일은 다 할 수 있다면 아마 기적적일 것입니다. 
제 의견으로는요.

143
00:09:03,078 --> 00:09:04,703
그러나 실제로, 그것은 작동 할뿐만 아니라,

144
00:09:04,703 --> 00:09:09,278
그러나 그런 것들은 약간의 제한된 상황에서는 
인간의 정확도와 유사하게 동작할 수도 있습니다.

145
00:09:09,278 --> 00:09:12,379
수행하는데 수백 ms 밖에 걸리지 않습니다.

146
00:09:12,379 --> 00:09:14,921
이것은 상당히 놀랍고 대단한 기술입니다.

147
00:09:14,921 --> 00:09:22,241
수업의 나머지는 어떤 종류의 진보가 이를 가능하게 
했는지를 살펴 볼 것입니다.

148
00:09:23,492 --> 00:09:27,565
자 그러면, 만약 여러분이 Image 분류기를 위한
API에 대해 고민하고 있다고 해 보자면,

149
00:09:27,565 --> 00:09:31,131
여러분은 아마 이런식의 Python 메서드를
작성 해 보려 할 지 모르겠습니다.

150
00:09:31,131 --> 00:09:34,401
이미지를 입력받고 
어떤 놀라운 마법이 일어난 뒤

151
00:09:34,401 --> 00:09:38,180
그러고 나서는 이 "이미지는 고양이"다, "개다" 라고 말해주는 
클래스 레이블이 튀어 나오는 것입니다.

152
00:09:38,180 --> 00:09:41,695
그리고 이걸 할 수 있는 확실한 묘안이 떠오르진 
않을 것입니다. 그렇죠?

153
00:09:41,695 --> 00:09:43,476
여러분이 알고리즘 수업을 듣고 있고,

154
00:09:43,476 --> 00:09:46,837
여러분이 할 일이 "숫자를 정렬"하거나 
"convex hull을 계산"하거나

155
00:09:46,837 --> 00:09:49,535
또는 "RSA 암호화" 같은 것이었다면

156
00:09:49,535 --> 00:09:55,773
여러분은 알고리즘을 써 내려가면서, 알고리즘이
동작하려면 필요한 모든 과정들을 나열할 것입니다.

157
00:09:55,773 --> 00:10:00,390
그러나 우리가 사물을 인식하려고 할 때,
고양이 또는 이미지를 인식하거나,

158
00:10:00,390 --> 00:10:07,909
객체를 인식하는 데 있어서는 그런 직관적이고 명시적인
알고리즘이 존재하지 않습니다.

159
00:10:07,909 --> 00:10:09,874
그러니 이것은 완전히 어려운 일입니다.

160
00:10:09,874 --> 00:10:13,447
만약 여러분이, 이제 막 첫 과제를 하려고 하고 있고

161
00:10:13,447 --> 00:10:15,464
이 함수를 작성하려고 하고 있을 때

162
00:10:15,464 --> 00:10:18,869
제 생각에는 대부분이 문제에 봉착 할 것입니다.

163
00:10:18,869 --> 00:10:19,740
즉,

164
00:10:19,740 --> 00:10:27,004
확실히, 지금껏 사람들은 서로 다른 동물들을 인식해 내기 위해서 
고오급 coded rules을 만들어내려는 시도를 해 왔습니다.

165
00:10:27,004 --> 00:10:29,193
우리는 마지막 강의에서 이를 조금 다룰것이지만

166
00:10:29,193 --> 00:10:32,095
고양이를 인식하는것에 대한 한 아이디어를 보자면

167
00:10:32,095 --> 00:10:35,596
우리는 고양이가 두 귀가 있고, 입이 있고 코가 있다는 것을
알고 있습니다.

168
00:10:35,596 --> 00:10:37,945
또 우리는 Hubel과 Wiesel의 연구로부터

169
00:10:37,945 --> 00:10:41,641
시각 인식을 할때 edges가 아주 중요하다는 것도 
알 고 있습니다.

170
00:10:41,641 --> 00:10:43,820
그러니 우리가 시도해볼 수 있는 한가지가 있다면

171
00:10:43,820 --> 00:10:45,425
이미지의 edges를 계산하는 것입니다.

172
00:10:45,425 --> 00:10:50,983
그리고는 여러 코너와 경계선의 카테고리를 분류합니다.

173
00:10:50,983 --> 00:10:53,146
만약 세개의 선이 이런 식으로 만나면 이건 코너고,

174
00:10:53,146 --> 00:10:55,186
귀는 "여기에 코너 하나" "저기에 코너 하나"

175
00:10:55,186 --> 00:10:56,483
또 "저기에도 코너 하나" 가 있고

176
00:10:56,483 --> 00:11:01,608
이런 식으로, 고양이를 인식하기 위해서 
이런 식으로 "명시적인 규칙 집합" 을 써 내려 가는 것입니다.

177
00:11:01,608 --> 00:11:04,391
아지만 이런 방식은 잘 동작하지 않는 다는 것이 밝혀졌습니다.

178
00:11:04,391 --> 00:11:06,127
한가지 이유는, 이런 알고리즘은
강인하지 못하다는 것이고

179
00:11:06,127 --> 00:11:15,005
두번째는, 우리가 또 다른 객체를 가지고 한다 치면, 고양이는 신경쓰지
않은채로 트럭에 대해서, 개에 대해서 만들게 될 것입니다.

180
00:11:15,005 --> 00:11:17,081
그러면 이 모든걸 다시 시작해야 합니다.

181
00:11:17,081 --> 00:11:19,853
즉, 이런 방법은 전혀 확장성있는 방법이 아닙니다.

182
00:11:19,853 --> 00:11:25,181
우리는 이 세상에 존재하는 다양한 객체들에게 유연하게
적용될 수 있는

183
00:11:25,181 --> 00:11:29,360
확장성 있는 알고리즘이나 방법을 만들고 싶었습니다.

184
00:11:31,311 --> 00:11:34,766
이런 일을 가능할 수 있게 만든 한 통찰은 바로

185
00:11:34,766 --> 00:11:38,092
데이터 중심 접근 방식에 대한 아이디어입니다.

186
00:11:38,092 --> 00:11:45,766
고양이는 무엇이다, 물고기는 무엇이다 하면서 손으로 
직접 어떤 규칙을 써내려 하는 것 대신에

187
00:11:45,766 --> 00:11:47,845
우리는 인터넷으로 가서

188
00:11:47,845 --> 00:11:55,402
엄청 많은 고양이 데이터, 엄청 많은 비행기 데이터, 엄청 많은
사슴 데이터를 포함한 방대한 데이터 셋을 수집하였습니다.

189
00:11:55,402 --> 00:11:59,138
그리고 우리는 다양한 카테고리들의 방대한 데이터들을 모으기 위해

190
00:11:59,138 --> 00:12:03,866
Google Image Search와 같은 도구들을 이용할 수 있었습니다.

191
00:12:03,866 --> 00:12:08,338
사실 그렇게 방대한 량의 데이터를 모으는 것은 엄청나게
많은 노력이 필요합니다.

192
00:12:08,338 --> 00:12:14,105
다행히도 우리가 사용할 수 있는 고퀄의 데이터셋들이 존재합니다.

193
00:12:14,105 --> 00:12:16,073
우리가 데이터셋을 얻고 나면

194
00:12:16,073 --> 00:12:20,869
우리는 그 모든 데이터를 집어 삼킬 기계학습 분류기를
학습시킵니다.

195
00:12:20,869 --> 00:12:28,446
그럼 알고리즘은 어떤 식으로든 데이터를 요약해서는 서로 다른 객체들을
인식할 수 있는 어떤 모델을 뱉어냅니다.

196
00:12:28,446 --> 00:12:31,756
그리고 최종적으로 이 학습 모델을 새로운 이미지에 
적용시키게 되면

197
00:12:31,756 --> 00:12:35,930
이 모델은 고양이나 개를 인식해 낼 수 있을 것입니다.

198
00:12:35,930 --> 00:12:38,428
이 부분에서 API 가 조금 변경되었습니다.

199
00:12:38,428 --> 00:12:42,099
이미지를 입력하면 고양이를 인식하는 단일 함수가 있는 것 대신에

200
00:12:42,099 --> 00:12:43,621
우리는 이제 함수가 두 개 있는 것입니다.

201
00:12:43,621 --> 00:12:49,115
하나는 학습을 위한 것이고, 이미지와
레이블을 입력으로 주면 모델을 출력합니다.

202
00:12:49,115 --> 00:12:52,030
그리고 별도적으로 또 하나의 함수는
예측 함수인데

203
00:12:52,030 --> 00:12:55,276
모델을 입력하면 이미지를 예측해 주는 것입니다.

204
00:12:55,276 --> 00:12:56,780
이것은 key insight입니다.

205
00:12:56,780 --> 00:13:01,928
이 key insight은 지난 10-20년간  
모든 것이 실제로 잘 동작하게 해 줬습니다.

206
00:13:05,784 --> 00:13:11,111
이 수업은 주로 신경망, CNN, 딥러닝 과 같은 것들을
다룹니다.

207
00:13:11,111 --> 00:13:15,819
하지만 데이터 중심이라는 아이디어는 단지 딥러닝에서
뿐만 아니라 좀 더 일반적으로 퍼져있던 개념입니다.

208
00:13:15,819 --> 00:13:19,145
제생각에는 좀 더 복잡하고 어려운 것을 하기 전에

209
00:13:19,145 --> 00:13:23,058
엄청 간단한 분류기를 한번 다뤄보고 가는것이
좋을 것 같습니다.

210
00:13:23,058 --> 00:13:28,907
아마도 여러분이 상상할 수 있는 가장 단순한 분류기가
있는데 우리는 이것을 nearest neighbor라고 부릅니다.

211
00:13:28,907 --> 00:13:31,243
알고리즘은 솔직히 너무 단순하긴 합니다.

212
00:13:31,243 --> 00:13:34,315
그래서 학습 스텝에서 우리는
아무 일도 하지 않을 것입니다.

213
00:13:34,315 --> 00:13:39,108
단지 모든 학습 데이터를 기억할 뿐입니다.
엄청 쉽습니다

214
00:13:39,108 --> 00:13:43,191
예측 스텝에서는
새로운 이미지가 주어지면

215
00:13:43,191 --> 00:13:47,964
새로운 이미지와 학습 데이터의 유사성을 비교해서

216
00:13:47,964 --> 00:13:51,453
가장 유사한 이미지로 레이블링을 예측하는 것입니다.

217
00:13:51,453 --> 00:13:53,169
아주 간단한 알고리즘 입니다.

218
00:13:53,169 --> 00:13:58,771
하지만 데이터 중심 방법론이라는 관점에서는
좋은 점들이 많다고 볼 수 있습니다.

219
00:13:59,977 --> 00:14:01,680
좀 더 구체적으로 들어가 보자면

220
00:14:01,680 --> 00:14:04,951
여러분들은 CIFAR-10 데이터셋을 다루게 될 것입니다.

221
00:14:04,951 --> 00:14:09,259
이 데이터셋은 기계학습 분야에서 아주 널리 쓰이며
일종의 작은 테스트용 데이터셋입니다.

222
00:14:09,259 --> 00:14:11,579
그리고 여러분들은 과제에서 이 데이터셋을 
다루게 될 것입니다.

223
00:14:11,579 --> 00:14:15,159
CIFAR-10 데이터 셋은 
10 가지 클래스를 제공합니다.

224
00:14:15,159 --> 00:14:19,920
비행기와 자동차, 새와 고양이 등이 있습니다.

225
00:14:19,920 --> 00:14:24,990
10개의 각 카테고리가 있고
50,000여개의 학습 이미지를 제공합니다.

226
00:14:27,173 --> 00:14:30,250
50,000개의 데이터가 각 카테고리에 
균등하게 분포하고 있습니다.

227
00:14:30,250 --> 00:14:37,565
그리고 여러분들이 알고리즘을 테스트하는데 사용하게될
10,000여개의 테스트 이미지가 있습니다.

228
00:14:38,707 --> 00:14:45,741
그러면 이 CIFAR-10 테스트 이미지에 
간단한 NN 예제를 적용 해 보겠습니다.

229
00:14:45,741 --> 00:14:53,693
오른쪽 칸의 제일 왼쪽 줄은
CIFAR-10의 테스트 이미지입니다.

230
00:14:53,693 --> 00:14:58,375
그리고 그 오른쪽 이미지들은 
학습 이미지를 분류하고

231
00:14:58,375 --> 00:15:03,571
각각의 테스트 예제와 가장 유사한 학습 이미지를
보여줍니다.

232
00:15:03,571 --> 00:15:07,938
테스트 이미지들이 학습 이미지와 비교했을때
눈으로 보기에는 꽤 비슷하게 생겼습니다.

233
00:15:07,938 --> 00:15:10,974
뭐 항상 맞는것은 아니지만 말입니다. 그렇죠?

234
00:15:10,974 --> 00:15:14,687
두번째 행을 보면, 사실 이게 좀 보기 힘듭니다

235
00:15:14,687 --> 00:15:21,224
이미지들이 32 x 32 픽셀로 되어 있기 때문에 
좀 더 유심히 보고 짐작해 보시기 바랍니다.

236
00:15:21,224 --> 00:15:23,850
어찌됐든, 두번째 행의 이미지는 개 입니다.
바로 옆에 있는 NN도 개 입니다.

237
00:15:23,850 --> 00:15:30,006
하지만 그 다음에 있는건 "사슴"이나 "말"같이 보이는군요

238
00:15:30,006 --> 00:15:33,237
하지만 여러분들은 얘네가 눈으로 보기에는
아주 유사해 보인다는 것을 알 수 있습니다.

239
00:15:33,237 --> 00:15:36,370
중간에 흰색 뭉텅이가 있거나 하는 식으로 보면 말이죠

240
00:15:36,370 --> 00:15:39,651
그래서 우리가 이 이미지에 NN 알고리즘을 적용한다면,

241
00:15:39,651 --> 00:15:42,707
우리는 트레이닝 셋에서 "가장 가까운 샘플"을 찾게 될 것입니다.

242
00:15:42,707 --> 00:15:47,135
우리는 그렇게 찾은 "가장 가까운 샘플"의 레이블을 알 수 
있습니다. 이 샘플들은 학습 데이터에서 나온 것이기 때문입니다

243
00:15:47,135 --> 00:15:50,875
그래서 우리는 이 테스트 이미지 또한 "개"이다 라는 것을
쉽게 알 수 있을 것입니다.

244
00:15:50,875 --> 00:15:55,851
여러분들이 이 예제가 엄청 잘 동작하지 않을것 
같다고 생각하실 수도 있지만

245
00:15:55,851 --> 00:16:00,018
그럼에도 이 예제는 해볼만한 아주 좋은 예제입니다.

246
00:16:00,939 --> 00:16:03,724
하지만 한가지 알아야 할 것은

247
00:16:03,724 --> 00:16:06,908
이미지 쌍이 주어졌을때
어떻게 그것들을 비교할지에 관한 것입니다.

248
00:16:06,908 --> 00:16:10,573
왜냐면 우리가 테스트 이미지를 하나 고르고 
이것을 모든 학습 이미지들과 비교한다 했을때

249
00:16:10,573 --> 00:16:12,165
사실 여러가지 방법이 있을 수 있습니다.

250
00:16:12,165 --> 00:16:15,640
정확히는, 비교 함수가 어떻게 생겼는지에 달렸습니다.

251
00:16:15,640 --> 00:16:20,008
이전 슬라이드의 예제에서는
L1 Distance라는 것을 사용했습니다.

252
00:16:20,008 --> 00:16:22,547
Manhattan distance 라고도 하지요

253
00:16:22,547 --> 00:16:27,448
이미지들을 비교할 때 이 방법은 아주 쉽고
단준한 방법입니다.

254
00:16:27,448 --> 00:16:32,969
이미지간의 각각의 개별적인 픽셀 하나 하나를 
비교하는 것입니다.

255
00:16:32,969 --> 00:16:39,346
테스트 이미지가 4x4 이미지라고 생각해보면

256
00:16:39,346 --> 00:16:43,172
그러고 테스트 이미지의 픽셀 하나를

257
00:16:43,172 --> 00:16:46,242
같은 자리의 트레이닝 이미지의 픽셀로 뺴줍니다. 
그리고 그 값의 절댓값을 취합니다

258
00:16:46,242 --> 00:16:49,068
그러면 두 이미지간의 픽셀의 차이 값을 
계산한 것입니다.

259
00:16:49,068 --> 00:16:51,950
그리고 이미지 내 모든 픽셀의 수행 결과를 모두 더합니다.

260
00:16:51,950 --> 00:16:54,213
이런 방식으로 이미지를 분류하는 것은
어리석은 일이지만

261
00:16:54,213 --> 00:16:57,963
하지만 여전히 생각해볼 만한 것들도 있습니다.

262
00:16:57,963 --> 00:17:01,991
이 방법은 두 이미지의 차이를 측정할 수 있는
아주 구체적인 방법을 제시합니다.

263
00:17:01,991 --> 00:17:07,147
이 예제의 경우에는 두 이미지간에
456이라는 차이가 있습니다.

264
00:17:08,446 --> 00:17:13,233
NN 분류기를 구현한 전체 Python 코드가 있습니다.

265
00:17:13,233 --> 00:17:16,582
상당히 짧고 간결하다는 것을 알 수 있습니다.

266
00:17:16,583 --> 00:17:21,348
NumPy에서 제공하는 Vectorizaed 연산을
이용했기 떄문입니다.

267
00:17:21,348 --> 00:17:26,247
여기에서는 우리가 얼마전에 얘기했던 
학습과 관련된 함수를 볼 수 있는데

268
00:17:26,247 --> 00:17:28,946
NN의 경우 아주 단순하죠

269
00:17:28,946 --> 00:17:33,427
단지 학습 데이터를 기억하는 것입니다.
크게 할 일이 딱히 없습니다

270
00:17:33,427 --> 00:17:39,126
이제 테스트 함수에서는 이미지를 입력으로 받고
이를 L1 Distance를 이용해서 비교합니다

271
00:17:39,126 --> 00:17:45,395
학습 데이터와 테스트 이미지를 가지고 비교를 해서 
트레이닝 셋에서 가장 유사한 것들을 찾아냅니다.

272
00:17:45,395 --> 00:17:50,113
그리고 그 일은 Python code 한 두 줄이면 충분합니다.

273
00:17:50,113 --> 00:17:53,882
Numpy의 vectorized 연산을 이용해서 말이죠

274
00:17:53,882 --> 00:17:57,779
여러분들은 첫 과제에서 이 것들을
연습하게 될 것입니다.

275
00:17:58,628 --> 00:18:02,179
그러면, 이 간단한 분류기에 대해서 
몇가지 물음이 있을 수 있겠습니다.

276
00:18:02,179 --> 00:18:04,910
첫째, 우리의 트레이닝 셋에 N개의 이미지가 들어있다면

277
00:18:04,910 --> 00:18:09,077
트레이닝, 테스트 속도가 얼마나 될까 하는 것입니다

278
00:18:12,233 --> 00:18:17,878
딱히 일이 없는 트레이닝쪽은 속도는 상수시간 일 것입니다.
단지 데이터를 기억하고 있는 것이죠. O(1)

279
00:18:17,878 --> 00:18:22,703
pointer를 사용해서 복사한다면, 데이터가 얼마나 크던
상수시간으로 끝날 수 있을 것입니다.

280
00:18:22,703 --> 00:18:31,099
하지만 테스트를 할때는 N개의 모든 학습용 데이터를 
테스트 이미지와 비교해야만 합니다.

281
00:18:31,099 --> 00:18:33,766
그리고 이 일은 실제로 너무 느립니다.

282
00:18:34,991 --> 00:18:38,641
하지만 생각해보면 이건 완전 "거꾸로" 된 것입니다.
(Train TIme < Test  TIme)

283
00:18:38,641 --> 00:18:45,326
실용적인 측명으로 보면 우리는 "학습 시간이 느리고"
"테스트 시간은 빠르길" 원합니다

284
00:18:45,326 --> 00:18:49,882
왜냐하면, 여러분이 데이터 센터같은 곳에서 어떤 분류기를
학습시키고 있다고 생각해보면

285
00:18:49,882 --> 00:18:54,640
좋은 성능의 분류기를 만들기 위해서 "학습"하는데
많은 시간을 들일 수 있을 것입니다.

286
00:18:54,640 --> 00:18:57,566
하지만 여러분이 이 분류기를 
"테스트"하려 한다고 생각해보면

287
00:18:57,566 --> 00:19:02,248
여러분이 그것을 핸드폰이나, 브라우저와 같은
low power device에서 돌려보고 싶을 수 있고

288
00:19:02,248 --> 00:19:07,075
여러분은 여러분의 분류기가 어느정도 빠른 성능을
보이길 원할 것입니다.

289
00:19:07,075 --> 00:19:11,826
그런 관점에서 보면 NN 알고리즘은 사실
거꾸로 된 경우인 것입니다.

290
00:19:11,826 --> 00:19:16,420
그리고 CNN이나 그런 부류의 parametic 모델을
생각해보면

291
00:19:16,420 --> 00:19:18,286
NN과 정 반대하는 것을 알 수 있습니다.

292
00:19:18,286 --> 00:19:24,936
학습 시간은 오래 걸리겠지만 
테스트 시간을 완전 빠를 것입니다.

293
00:19:24,936 --> 00:19:30,816
 NN알고리즘을 우리가 실제로 적용했을 때 정확히
어떤식으로 보일지에 대한 물음이 남아있습니다.

294
00:19:30,816 --> 00:19:36,130
여기에 우리가 NN의 decision regions 이라는 것을
그려 보았습니다.

295
00:19:36,130 --> 00:19:42,021
여기 2차원 평면에 이 점들은
학습 데이터들 입니다.

296
00:19:42,021 --> 00:19:47,547
그리고 점의 색은 그 점의 카테고리, 즉 클래스 레이블을 나타냅니다.

297
00:19:47,547 --> 00:19:49,221
여기에는 5개의 클래스가 있다는 것을 알수 있습니다.

298
00:19:49,221 --> 00:19:51,543
저 위 구석에는 파란색이 있고

299
00:19:51,543 --> 00:19:53,921
오른쪽 위에는 보라색이 있고

300
00:19:53,921 --> 00:19:56,491
그리고 이제 전체 평면의 모든 픽셀에 대해서

301
00:19:56,491 --> 00:20:02,560
각 픽셀이 어떤 학습 데이터와 가장 가까운지를 계산했습니다.

302
00:20:02,560 --> 00:20:06,954
그런 다음 해당 클래스 레이블에 해당하는 색으로 칠했습니다.

303
00:20:06,954 --> 00:20:11,032
이는 NN 분류기를 일종의 공간을 분할하는 작업을 수행하고

304
00:20:11,032 --> 00:20:14,979
해당하는 색을 칙하는 것으로 볼 수 있습니다.

305
00:20:14,979 --> 00:20:18,320
하지만 이 분류기는 엄청 좋다고는 할 수 없습니다.

306
00:20:18,320 --> 00:20:24,676
이 그림을 보면서 우리는 이 NN 분류기에서 발생할지
모르는 문제들에 대해서 살펴볼 수 있습니다.

307
00:20:24,676 --> 00:20:31,591
하나 들자면, 가운데에는 대부분이 초록점인데
중간에 노란 점 하나가 있습니다.

308
00:20:31,591 --> 00:20:38,552
하지만 우리는 단지 "가장 가까운 이웃" 만을 보기 때문에 이는 
녹색의 무리 한개운데 "노란색 섬" 을 나타나게 합니다.

309
00:20:38,552 --> 00:20:40,087
아마 이것은 좋은 일은 아닐 것입니다.

310
00:20:40,087 --> 00:20:44,081
아마 그런 점들도 초록색이어야 할 것입니다.

311
00:20:44,081 --> 00:20:50,225
그리고 비슷하게 파란색 지역을 침범하고 있는
"손가락 모양의 초록색 지역"또한 볼 수 있는데

312
00:20:50,225 --> 00:20:55,180
이것은 한 점이 그곳에 있어서 그런데,
아마 이 점은 잡음(noise)이거나 가짜(spurious)일 것입니다.

313
00:20:55,180 --> 00:21:01,606
이런 것들은, NN의 조금 더 일반화된 버전인
k-NN 알고리즘이 만들어진 동기가 되었습니다.

314
00:21:01,606 --> 00:21:05,070
단순하기 하나의 가장 가까운 이웃을 탐색하기 보다는

315
00:21:05,070 --> 00:21:08,021
대신에 우리는 좀더 멋있는 것을 할 것입니다.

316
00:21:08,021 --> 00:21:10,627
일종의 distance metric을 이용해서 
K개의 가까운 이웃을 찾는 것입니다.

317
00:21:10,627 --> 00:21:15,057
그리고 여러 이웃들끼리 투표를 하는 것입니다.

318
00:21:15,057 --> 00:21:18,733
그리고 여러 이웃들 중 가장 많은 득표수를 가진 것으로
예측하는 것입니다.

319
00:21:18,733 --> 00:21:21,032
아마 여러분은 이를 위해서는 약간은 더 복잡한 방법이 
필요할 것이라고 생각해 볼 수 있을 것입니다.

320
00:21:21,032 --> 00:21:24,148
거리별로 가중치를 가지고 투표를 한다던가 
하는 것들이 있겠지요

321
00:21:24,148 --> 00:21:27,912
하지만 가장 잘 동작하는 제일 쉬운 방법은

322
00:21:27,912 --> 00:21:29,810
그저 가장 많은 득표수를 취하는 것입니다.

323
00:21:29,810 --> 00:21:35,899
정확히 같은 데이터를 사용한 k-nn 분류기들이 있습니다.

324
00:21:35,899 --> 00:21:39,928
K=1 일때가 있고, 중앙과 오른쪽에는  K=3일떄
K = 5 일때가 있습니다.

325
00:21:39,928 --> 00:21:43,792
K=3 일때는 살보자면

326
00:21:43,792 --> 00:21:50,966
이전에 초록색 무리 중안에 자리잡고있었던 노란색 점이 더 이상 노란 지역을
만들어내지 않는다는 것을 알 수 있습니다.

327
00:21:50,966 --> 00:21:55,852
이제는 중앙의 초록색 부분은 완전하게
초록색으로 분류되고 있습니다.

328
00:21:55,852 --> 00:21:59,272
그리고 빨간색과 파란색 영역 사이의 손가락들이

329
00:21:59,272 --> 00:22:00,823
점점 부드러워지기 시작했습니다.

330
00:22:00,823 --> 00:22:02,454
다수결로 인한 것이죠.

331
00:22:02,454 --> 00:22:05,381
K=5의 경우를 보자면

332
00:22:05,381 --> 00:22:08,437
파란색과 빨간색 영역 사이의 결정경계가

333
00:22:08,437 --> 00:22:12,064
아주 부드럽고 훌륭하게 만들어 졌습니다.

334
00:22:12,064 --> 00:22:14,727
대게 여러분이 NN분류기를 사용하게 된다면

335
00:22:14,727 --> 00:22:20,771
여러분들은 대게 1보다는 큰 값의 K를 사용하고 싶을 것입니다.

336
00:22:20,771 --> 00:22:26,064
왜냐하면 K가 1보다 큰 것이 결정 경계를 더 부드럽게 하고 
더 좋은 결과를 이끌어 주기 때문입니다.

337
00:22:29,252 --> 00:22:30,159
질문있나요?

338
00:22:30,159 --> 00:22:34,279
[질문하는 학생]

339
00:22:34,279 --> 00:22:35,208
알겠습니다. 질문은

340
00:22:35,208 --> 00:22:38,133
"흰색 지역은 어떻게 처리하나요?" 인데요

341
00:22:38,133 --> 00:22:43,247
흰색 영역은 k-nn에서 "대다수"를 결정할 수 없는 지역입니다.

342
00:22:43,247 --> 00:22:45,521
여러분들은 조금 더 좋은 방법을 생각할 수 있을 것입니다.

343
00:22:45,521 --> 00:22:50,472
어떤 식으로든 추론을 해보거나 임의로 정할 수도 있겠지요

344
00:22:50,472 --> 00:22:55,668
하지만 여기 단순한 예제에서는 이 곳에서는 가장 가까운 이웃이 
존재하지 않음을 나타내기 위해서 흰색으로 칠했습니다.

345
00:23:00,005 --> 00:23:02,439
우리가 컴퓨터비전에 대해 생각하는데 있어서

346
00:23:02,439 --> 00:23:06,616
다양한 관점을 유연하게 다루는 능력이 매우 유용하다고 생각합니다.

347
00:23:06,616 --> 00:23:09,480
하나는 고차원 공간에 존재하는 점들 이라는 측면이고

348
00:23:09,480 --> 00:23:13,049
다른 하나는 그저 실제 이미지로 보는 것입니다.

349
00:23:13,049 --> 00:23:19,048
왜냐하면 이미지의 픽셀들은 이미지를 고차원 벡터로 
여길 수 있게 해주기 때문입니다.

350
00:23:19,048 --> 00:23:23,395
이런 두가지 측면을 왔다 갔다 할 수 있는 것은 매우 유용합니다.

351
00:23:23,395 --> 00:23:27,876
다시 k-nn을 가지고 이미지로 돌아가 보자면

352
00:23:27,876 --> 00:23:29,443
여러분들은 k-nn이 별로 안좋다는 것을 알 수 있습니다.

353
00:23:29,443 --> 00:23:35,385
제가 여기에 잘 분류되었는지 
아닌지를 초록색과 빨간색으로 표시해 놨습니다.

354
00:23:35,385 --> 00:23:38,288
그리고 정말 안좋아 보입니다.

355
00:23:38,288 --> 00:23:41,459
하지만 더 큰 K값을 사용한다면

356
00:23:41,459 --> 00:23:47,264
투표를 하는데 제일 유사한 하나만 쓰는것이 아니라
상위 세개, 혹은 다섯개, 심지어는 행 전체를 이용할 수도 있을 것입니다.

357
00:23:47,264 --> 00:23:55,325
더 많은 이웃을 고려하면서 이웃들을 검색하게 되면 
여러 잡음에 더 강인해 질 것임을 상상해 볼 수 있습니다.

358
00:23:57,070 --> 00:24:01,666
우리가 k-nn 알고리즘에서 결정해야할 다른 한가지가 있습니다.

359
00:24:01,666 --> 00:24:05,727
그것은 바로 서로 다른 점들을 어떤 방식으로 비교해야 하는지 입니다.

360
00:24:05,727 --> 00:24:11,666
지금까지는 L1 Distance만을 예제로 봐 왔습니다.

361
00:24:11,666 --> 00:24:15,126
이는 픽셀간의 차이의 절대값의 합을 이용하는 것입니다.

362
00:24:15,126 --> 00:24:18,299
하지만 또다른 선택지중 하나는 바로 
L2, 즉 Euclidean distance인데

363
00:24:18,299 --> 00:24:24,491
제곱들의 합의 제곱근을 거리로 이용하는 것입니다.

364
00:24:24,491 --> 00:24:28,727
다른 거리 측정 기준을 고르는 것은 아주 흥미로운 주제입니다.

365
00:24:28,727 --> 00:24:30,072
왜냐하면 서로 다른 거리측정 기준은

366
00:24:30,072 --> 00:24:35,386
그 공간에서 기대할 수 있는 근본적인 기하학적 구조에
대한 새로운 가정을 세우기 떄문입니다.

367
00:24:35,386 --> 00:24:41,688
왼쪽에 보이는 L1 Distance는 사실 L1 Distance의
입장에서는 원입니다. (모양은 사각형)

368
00:24:41,688 --> 00:24:45,020
그리고 원점을 기준으로 하는 사각형의 모양입니다.

369
00:24:45,020 --> 00:24:47,637
각 점들은 이 사각형 위에 존재하며

370
00:24:47,637 --> 00:24:51,017
L1에 따르면 이 점들은 모두 같은 거리에 존재하는 것입니다. 
(L1의 입장에서는 모두 같은 거리에 있는 점들의 집합이니 원임)

371
00:24:51,017 --> 00:24:53,116
반면 L2, Euclidean distance의 경우에는

372
00:24:53,116 --> 00:24:55,290
이 원이 바로 우리에게 익숙한 원이죠

373
00:24:55,290 --> 00:24:57,241
L2의 모양은 우리가 예상한 그대로 입니다.

374
00:24:57,241 --> 00:25:00,798
이 두 metrics간에 아주 흥미로운 차이가 있는데

375
00:25:00,798 --> 00:25:05,135
L1 Distance는 여러분의 좌표 시스템의 선택에 
영향을 받는다는 것입니다.

376
00:25:05,135 --> 00:25:07,306
그러니까, 여러분이 좌표계를 회전시키거나 하면

377
00:25:07,306 --> 00:25:10,201
점들 간의 L1 distance가 바뀌게 되는 것입니다.

378
00:25:10,201 --> 00:25:18,281
반면 L2 Distance의 경우에는 어떤 좌표계와 아무 상관이 없습니다.

379
00:25:18,281 --> 00:25:24,791
만약 입력된 특징벡터 안의 각각 요소들이 어떤 중요한
의미를 가지고 있다면

380
00:25:24,791 --> 00:25:27,935
L1 Distance가 더 잘 맞을 수도 있을지 모릅니다.

381
00:25:27,935 --> 00:25:30,533
그러나 그것이 어떤 공간에서의 일반적인 벡터 일 경우에는

382
00:25:30,533 --> 00:25:34,121
그리고 우리가 그 벡터 요소들간에 어떤 실질적인 의미가
있는지를 잘 알지 못한다면

383
00:25:34,121 --> 00:25:37,531
아마도 L2 Distance가 조금은 더 잘 맞을 수 있습니다.

384
00:25:37,531 --> 00:25:41,839
서로 다른 거리 척도를 사용하는 것에 대해서
또다른 주목할 점은 바로

385
00:25:41,839 --> 00:25:46,343
우리는 다양한 많은 타입의 데이터를 K-NN 분류기를 통해
일반화 시킬 수 있습니다.

386
00:25:46,343 --> 00:25:48,280
단지 벡터나 이미지에서 뿐만이 아닌 것입니다.

387
00:25:48,280 --> 00:25:51,410
에를 들어 여러분이 어떤 문장을 분류하는 일이 있다고 생각해 보면

388
00:25:51,410 --> 00:25:55,366
우리가 k-nn 분류기를 이 문제에 사용하기 위해 해야할 일은 그저

389
00:25:55,366 --> 00:25:57,716
어떤 거리 척도를 사용할지를 정하는 것입니다.

390
00:25:57,716 --> 00:26:03,831
그 척도가 될 수 있는것은 두 문장간의 거리를 측정할 수 
있는 어떤것이든 가능합니다.

391
00:26:03,831 --> 00:26:12,701
어떤 거리 척도를 사용할지를 정하는 것 만으로 우리는 
이 알고리즘은 어떤 종류의 데이터에도 일반적으로 적용할 수 있습니다.

392
00:26:12,701 --> 00:26:20,283
비록 이 알고리즘이 단순하긴 하지만 어떤 새로운 문제를
접하고 있을때 시도해볼만한 좋은 수단이 될 수 있는 것입니다.

393
00:26:21,805 --> 00:26:28,441
자 그러면 다양한 거리 측정 기준을 선택함으로써 
실제 기하학적으로 어떤 변화가 일어나는지 생각해 봅시다.

394
00:26:28,441 --> 00:26:33,577
여기 같은 데이터를 가지고 비교한 두개의 모델이 있는데

395
00:26:33,577 --> 00:26:38,087
왼쪽에는 L1 Distance를 사용했고, 오른쪽은 L2 Distance를
사용한 것입니다.

396
00:26:38,087 --> 00:26:44,093
그리고 두 개의 척도 사이에 실제 결정 경계의 모양이
서로 다름을 알 수 있습니다.

397
00:26:44,093 --> 00:26:49,337
왼쪽의 L1 Distance를 보자면 이는 결정 경계가 
좌표 축의 영향을 받는 경향이 있음을 알 수 있습니다.

398
00:26:49,337 --> 00:26:53,451
다시 말하지만, L1 Distance는 우리가 좌표 시스템을
어떻게 선택하는지에 영향을 받기 때문입니다.

399
00:26:53,451 --> 00:27:00,294
반명 L2 Distance는 촤표축을 신경쓰지 않고 결정 경계를 
만들기 때문에 좀 더 자연스러워 보입니다.

400
00:27:04,161 --> 00:27:08,669
사실 지금까지 보여드린 모든 예제는

401
00:27:08,669 --> 00:27:14,618
제가 만든 웹 데모사이트에서 가져온 것입니다. 여기에서는
여러분만의 k-nn 분류기를 만들어 볼 수 있습니다.

402
00:27:14,618 --> 00:27:17,938
이 프로텍터 스크린으로 보여드리기가 참 어렵군요

403
00:27:17,938 --> 00:27:21,271
집에가서 한번 해보시기 바랍니다.

404
00:27:26,820 --> 00:27:29,403
다시 돌아가 봅시다

405
00:27:32,951 --> 00:27:35,784


406
00:28:07,103 --> 00:28:09,679
좋습니다 말썽이 좀 있었습니다

407
00:28:09,679 --> 00:28:13,496
여기에서는 웹 데모를 건너 뛸 것이지만 
여러분의 컴퓨터로 한번 꼭 해보시기 바랍니다.

408
00:28:13,496 --> 00:28:26,029
실제로는 상당히 재밌고 K 값이나 거리 척도가 바뀜에 따라서 어떻게 
결정 경계가 만들어지는지에 대한 직관을 얻을 수 있습니다.

409
00:28:30,641 --> 00:28:34,072
좋습니다. 그러면 여기에서의 질문은 바로 
우리가 실제로 알고리즘을 사용하려고 할때

410
00:28:34,072 --> 00:28:37,178
우리가 선택해야만 하는 몇가지 항목이 있다는 것입니다.

411
00:28:37,178 --> 00:28:39,426
이전에 다양한 K값의 대해서 이야기했습니다.

412
00:28:39,426 --> 00:28:41,520
L1/L2와 같은 거리의 척도에 관해서도 이야기 했습니다.

413
00:28:41,520 --> 00:28:47,286
그리고 그 질문은 "어떻게 우리의 문제나 데이터에 맞는 
그런 결정을 할 수 있는지" 가 됩니다.

414
00:28:47,286 --> 00:28:53,937
K나 거리척도와 긑은 것들을 우리는 
"하이퍼 파라미터" 라고 부릅니다.

415
00:28:53,937 --> 00:28:57,289
하이퍼 파라미터는 트레이닝 데이터로부터 학슴할 수 있는
것이 아니기 떄문에

416
00:28:57,289 --> 00:29:01,313
대신 여러분이 학습하기 전에 사전에 선택해야만 합니다.

417
00:29:01,313 --> 00:29:05,623
데이터에서 직접적으로 배울 방법은 없습니다.

418
00:29:05,623 --> 00:29:10,260
그럼 다음 질문은 "실제로는 하이퍼 파라미터는 어떻게 정하는지" 
입니다.

419
00:29:10,260 --> 00:29:12,277
그리고 그건 매우 문제의존적(problem-dependent)입니다.

420
00:29:12,277 --> 00:29:17,957
대부분의 사람들이 하는 가장 단순한 방법은 바로  데이터에 맞게
다양한 하이퍼파라미터 값을 시도해 보는 것입니다.

421
00:29:17,957 --> 00:29:20,950
그리고 어떤것이 가장 좋은지를 알아내는 것입니다.

422
00:29:20,950 --> 00:29:22,404
질문 있습니까?

423
00:29:22,404 --> 00:29:26,071
[질문하는 학생]

424
00:29:29,589 --> 00:29:34,447
질문은 "어디에서 L1 Distance가 L2 Distance보다 
더 좋은지" 입니다.

425
00:29:34,447 --> 00:29:36,800
제 생각에 그것은 정말 문제 의존적이고,

426
00:29:36,800 --> 00:29:41,204
이 경우에는 L1을 쓰고 이 경우에는 L2를 써라 라고
말하기가 참 어렵습니다만

427
00:29:41,204 --> 00:29:50,185
L1은 좌표계에 의존적이기 때문에 
여러분의 데이터가 좌표계에 의존적인지가 관건이라 생각합니다.

428
00:29:50,185 --> 00:29:55,513
만약 어떤 특징 벡터가 있고, 이 벡터의 각 요소가 어떤 의미를
지니고 있다면

429
00:29:55,513 --> 00:29:58,583
예를들어 여러분이 어떤 이유가 되었든
직원들을 분류하고자 한다면

430
00:29:58,583 --> 00:30:03,976
그 벡터의 다양한 요소 각각이 직원들의 서로다른 특징들에 
영향을 미치게 됩니다.

431
00:30:03,976 --> 00:30:08,778
그 요소는 봉급이라던지 회사 근속년수와 
같은 것들이 될 수 있겠지요

432
00:30:08,778 --> 00:30:11,860
각각의 요소가 어떤 의미를 가지고 있다면,

433
00:30:11,860 --> 00:30:15,850
L1 을 사용하는것이 좀 더 괜찮을 지도 모릅니다.

434
00:30:15,850 --> 00:30:19,989
다시 돌아가서, 일반적으로는 하이퍼 파라미터가
전적으로 어떤 문제인지, 그리고 어떤 데이터인지에 의존적입니다.

435
00:30:19,989 --> 00:30:24,381
하이퍼 파라미터를 어떻게 정하느냐에 대한 가장 좋은 답은
그저 여러 시도를 해보고 더 좋은 것을 선택하는 것입니다.

436
00:30:28,381 --> 00:30:32,413
다양한 하이퍼 파라미터 값들을 실험해보고 최상의 값을
구하는것에 있어서도

437
00:30:32,413 --> 00:30:34,238
여기에도 다양한 선택사항이 있을 수 있습니다.

438
00:30:34,238 --> 00:30:38,268
"다양한 하이퍼 파라미터를 시도해 본다는 것" 과
"그중 최고를 선택하는 것" 이 무슨 뜻일까요?

439
00:30:38,268 --> 00:30:42,911
아마 처음 떠오르는 아이디어는 아주 심플하게 선택하는 것인데

440
00:30:42,911 --> 00:30:47,691
그것은 여러분들의 학습데이터의 정확도와 성능을 최고로 끌어 
올릴 수 있는 하이퍼 파라미터를 선택하는 것입니다.

441
00:30:47,691 --> 00:30:49,961
사실 이건 정말 끔찍한 생각입니다.

442
00:30:49,961 --> 00:30:52,137
절대 해서는 안됩니다.

443
00:30:52,137 --> 00:30:55,717
NN 분류기로 구체적인 예를 들어보자면

444
00:30:55,717 --> 00:31:00,157
만약 우리가 K = 1로 둔다면 학습 데이터를
아주 완벽하게 분류할 것입니다.

445
00:31:01,124 --> 00:31:04,420
그러니 그런 방법(트레이닝 데이터의 정확도를 올리는)를 쓴다면
항상 K = 1 을 선택할 것입니다.

446
00:31:04,420 --> 00:31:06,390
하지만 우리가 좀 전에 예제에서도 봤듯이

447
00:31:06,390 --> 00:31:10,446
실제로는 K를 더 큰 값을 두는 것이

448
00:31:10,446 --> 00:31:13,184
학습 데이터에서 몇개는 잘못 분류할 수는 있지만

449
00:31:13,184 --> 00:31:17,915
실제로 학습 데이터에 없던 데이터의 경우에서는
더 좋은 성능을 보일 수 있습니다.

450
00:31:17,915 --> 00:31:19,208
그리고 궁극적으로 기계학습에서는

451
00:31:19,208 --> 00:31:24,463
학습 데이터에 얼마나 잘 맞는지가 중요한 것이 아니라 
우리가 학습시킨 분류기가

452
00:31:24,463 --> 00:31:27,051
학습 후에 한번도 보지 못한 데이터를 얼마나 잘 예측하는지가
중요한 것입니다.

453
00:31:27,051 --> 00:31:30,495
그러므로 트레이닝 데이터만 보는것은 정말 최악입니다.
비추입니다.

454
00:31:30,495 --> 00:31:34,856
그럼 또 다른 아이디어가 있을 수 있습니다. 
전체 데이터 셋을 가져와서는

455
00:31:34,856 --> 00:31:38,390
트레이닝 데이터를 쪼개서 일부를 테스트 데이터로 사용하는 것입니다.

456
00:31:38,390 --> 00:31:44,409
그럼 이제 학습 데이터로 다양한 하이퍼파라미터 값들로
학습을 시키고

457
00:31:44,409 --> 00:31:49,584
테스트 데이터에 적용시켜본 다음에

458
00:31:49,584 --> 00:31:53,716
최고의 성능을 가진 하이퍼 파라미터를 선택할 것입니다.

459
00:31:54,582 --> 00:31:57,414
이건 좀 더 합리적인 전략같이 보이지만

460
00:31:57,414 --> 00:31:59,546
그러나 사실은, 이 방법 또한 아주 끔찍한 생각입니다.

461
00:31:59,546 --> 00:32:01,087
절대 하면 안됩니다.

462
00:32:01,087 --> 00:32:06,515
왜냐하면, 다시 기계학습 시스템의 요지로 돌아가보자면 
우리는 알고리즘이 어떻게 작동할 지를 알고싶은 것입니다.

463
00:32:06,515 --> 00:32:08,017
그러니 테스트셋의 목적은

464
00:32:08,017 --> 00:32:14,523
한번도 보지 못했던 야생의 데이터에 우리 알고리즘이
어떻게 동작할지를 측정하는 것입니다.

465
00:32:14,523 --> 00:32:19,749
만약 우리가 이 전략으로 여러 하이퍼파라미터로 학습시켜보고

466
00:32:19,749 --> 00:32:23,363
테스트 데이터에서 가장 성능이 좋은 것을 뽑아낸다면

467
00:32:23,363 --> 00:32:31,663
그러면 우리는 그저 "그 테스트 셋에서만" 잘 맞는 하이퍼 
파라미터를 고른 것일수도 있습니다.

468
00:32:31,663 --> 00:32:38,280
그러면 현재 이 테스트셋에서 보인 성능은 더이상
새로운, 한번도 보지못한 데이터의 성능을 대표할 수 없는 것입니다.

469
00:32:38,280 --> 00:32:41,491
그러니 이것 또한 하지 말아야 합니다.
안좋은 생각입니다.

470
00:32:41,491 --> 00:32:44,672
그렇게 하면 곤경에 빠질 것입니다.

471
00:32:44,672 --> 00:32:49,192
훨씬 더 일반적인 방법은 데이터를 세개로 나누는 것입니다.

472
00:32:50,185 --> 00:32:57,305
데이터의 거의 대부분은 트레이닝 셋으로 나누고, 일부는
밸리데이션 셋, 그리고 테스트 셋으로 나누는 것입니다.

473
00:32:57,305 --> 00:33:03,500
그리고 일반적으로 하는 일은 다양한 하이퍼파라미터를 이용해서
"트레이닝 셋" 으로 알고리즘을 학습시키고

474
00:33:03,500 --> 00:33:11,621
"벨리데이션 셋" 으로 검증을 하고 벨리데이션 셋에서
최고의 성능을 보이는 하이퍼 파라미터를 선택하는 것입니다.

475
00:33:11,621 --> 00:33:13,719
그리고 개발을 다 마친 후에

476
00:33:13,719 --> 00:33:16,627
디버깅도 다 마치고
모든 것을 다 마친 후에

477
00:33:16,627 --> 00:33:21,614
그리고 벨리데이션 셋에서 가장 좋은 성능을 보인
분류기를 가지고서는

478
00:33:21,614 --> 00:33:23,401
테스트 셋은 "딱 한번만" 수행하는 것입니다.

479
00:33:23,401 --> 00:33:27,139
그 마지막 수치가 여러분들의 논문에 들어갈 것이고
또 여러분들의 보고서에도 들어갈 것이고

480
00:33:27,139 --> 00:33:32,393
그 숫자가 여러분의 알고리즘이 한번도 보지 못한 데이터에
얼마나 잘 동작해 주는지를 실질적으로 말해주는 것입니다.

481
00:33:32,393 --> 00:33:38,847
그리고 실제로 벨리데이션 데이터와 테스트 데이터를
엄격하게 나눠놓는 것은 상당히 중요합니다.

482
00:33:38,847 --> 00:33:45,653
예를 한가지 들어보자면, 우리는 연구 논문을 작성할때 
테스트 셋을 거의 마지막 쯤에야 한번 사용합니다.

483
00:33:45,653 --> 00:33:54,159
저는 논문을 쓸때 마감 일주일 전 부터만 테스트 셋을
사용합니다.

484
00:33:54,159 --> 00:33:57,961
우리는 정직하게 연구를 수행했고 논문의 수치는 공정하게 
측정했다는 것을 보장하기 위해서죠

485
00:33:57,961 --> 00:34:00,102
사실 이것을 정말로 중요합니다.

486
00:34:00,102 --> 00:34:03,883
여러분은 여러분의 테스트 데이터를 잘 통해해야만 합니다.

487
00:34:06,468 --> 00:34:10,840
또다른 하이퍼 파라미터와 관련된 전략은 바로 
크로스 벨리데이션(교차 검증) 입니다.

488
00:34:10,840 --> 00:34:17,317
이 방법은 작은 데이터셋일때 많이 사용하는 방법이고
딥 러닝에서는 많이 사용하진 않습니다.

489
00:34:17,317 --> 00:34:20,201
이 아이디에에서는 우선 테스트 데이터는 정해놓고

490
00:34:20,201 --> 00:34:25,534
그 테스트 데이터셋은 아주 마지막에만 씁니다

491
00:34:25,534 --> 00:34:31,265
그리고 나머지 데이터는 트레이닝 부분, 벨리데이션 부분 
으로 딱 나눠 놓는 것이 아니라

492
00:34:31,266 --> 00:34:35,515
대신에 트레이닝 데이터를 여러 부분으로 나누는 것 입니다.

493
00:34:35,516 --> 00:34:41,415
이런 식으로 돌아가면서 어떤 부분이 벨리데이션 셋으로
지정할지를 선택하는 것입니다.

494
00:34:41,415 --> 00:34:45,498
이 예제에서 우리는
5-Fold Cross Validation을 사용하고 있습니다.

495
00:34:45,498 --> 00:34:49,984
처음 4개의 fold에서 하이퍼 파라미터를 학습시키고

496
00:34:49,985 --> 00:34:51,928
남은 한 fold에서 알고리즘을 평가합니다.

497
00:34:51,928 --> 00:34:55,712
그리고 1,2,3,5 fold에서 다시 학습시키고

498
00:34:55,712 --> 00:34:57,769
4 fold로 평가합니다.

499
00:34:57,769 --> 00:35:00,293
이것을 계속 순환하는 것입니다.

500
00:35:00,293 --> 00:35:01,765
이런식으로 하게 되면

501
00:35:01,765 --> 00:35:07,511
어떤 하이퍼 파라미터가 더 강인한지데 대한
훨씬 더 높은 확인을 가질 수 있습니다.

502
00:35:07,511 --> 00:35:09,714
이런 방식은 거의 표준이긴 하지만

503
00:35:09,714 --> 00:35:13,285
실제로 딥러닝에서는 큰 모델을 학습시킬 때

504
00:35:13,285 --> 00:35:18,652
학습 자체가 계산량이 많기 때문에
실제로는 잘 쓰지 않습니다.

505
00:35:18,652 --> 00:35:19,519
질문 있습니까?

506
00:35:19,519 --> 00:35:23,186
[질문하는 학생]

507
00:35:29,515 --> 00:35:32,634
질문을 좀 더 구체적으로 말하자면

508
00:35:32,634 --> 00:35:35,728
트레이닝 셋과 벨리데이션 셋의 차이가 무엇인가 입니다.

509
00:35:35,728 --> 00:35:39,895
k-NN에 대해 생각해보자면

510
00:35:41,060 --> 00:35:46,974
트레이닝 셋은 우리가 레이블을 기억하고 있는 이미지들 입니다.

511
00:35:46,974 --> 00:35:52,451
그러면 이미지를 분류하기 위해서 이미지를 트레이닝 데이터의
각각의 이미지들과 비교하게 될 것입니다.

512
00:35:52,451 --> 00:35:56,618
그리고 가장 트레이닝 셋에서 가장 근접한 
곳으로 레이블링 하게 되는 것입니다.

513
00:36:00,052 --> 00:36:03,184
알고리즘은 트레이닝 셋의 모든 것을 기억할 것입니다.

514
00:36:03,184 --> 00:36:08,062
그리고 이제는 벨리데이션 셋을 가져와서는
트레이닝 데이터와 비교합니다.

515
00:36:08,062 --> 00:36:16,815
그리고 이를 통해서 분류기를 벨리데이션 셋에 적용했을 때
얼마만큼의 정확도가 나오는지 확인합니다.

516
00:36:16,815 --> 00:36:19,919
이것이 바로 트레이닝 셋과 벨리데이션 셋의 차이점 입니다.

517
00:36:19,919 --> 00:36:24,207
알고리즘은 트레이닝 셋의 레이블을 볼 수 있고

518
00:36:24,207 --> 00:36:28,473
벨리데이션 셋의 경우에는 직접적으로 접근할 수 없는 것입니다.

519
00:36:28,473 --> 00:36:34,043
우리는 벨리데이션 셋의 레이블을 알고리즘이 얼마나 잘 동작하고
있는지를 확인할때만 사용합니다.

520
00:36:34,043 --> 00:36:34,907
질문 있으십니까?

521
00:36:34,907 --> 00:36:38,574
[질문하는 학생]

522
00:36:44,373 --> 00:36:52,941
질문은, 이게 테스트 셋으로 나눠놓건 아니건 
어떻게  테스트 셋이 야생의 한번도 못본 데이터를 대표할 수 있는지 입니다.

523
00:36:52,941 --> 00:36:55,955
이것은 실제도 문제가 될 수 있습니다

524
00:36:55,955 --> 00:37:01,863
기본적인 통계학적 가정이 하나 있는데 여러분의 데이터는 독립적이며, 
유일한 하나의 분포에서 나온다는 것입니다 (i.i.d assumption)

525
00:37:01,863 --> 00:37:10,125
그러니 여러분들의 모든 데이터는 같은 
확률 분포에서 비롯되어야만 합니다.

526
00:37:10,125 --> 00:37:12,948
물론 실제로는 그런 항상 그런 경우는 없겠지만

527
00:37:12,948 --> 00:37:20,951
여러분은 분명히 테스트 셋이 야생의 데이터를 
엄청 잘 표현하지 못하는 경우를 경험하게 될 수 있습니다.

528
00:37:20,951 --> 00:37:25,473
그리고 이런 류의 문제는 datasets creators와
dataset curators가 생각해 볼 문제입니다.

529
00:37:25,473 --> 00:37:28,626
하지만, 예컨데 제가 데이터 셋을 만들때
하는 한가지 일은

530
00:37:28,626 --> 00:37:34,252
데이터를 수집하는 일관된 방법론을 가지고 
대량의 데이터를 한번에 수집하는 것입니다.

531
00:37:34,252 --> 00:37:38,690
그다음에 무작위로 트레이닝 데이터와 
테스트 데이터를 나누는 것입니다.

532
00:37:38,690 --> 00:37:43,024
한가지 여러분의 계획을 망칠 수 있는 것은 
데이터를 지속적으로 모으고 있는 경우

533
00:37:43,024 --> 00:37:46,343
먼저 수집한 데이터들을 트레이닝 데이터로 쓰고

534
00:37:46,343 --> 00:37:51,613
이후에 모은 데이터를 테스트 데이터로 사용한다면
문제를 이르킬 수 있는 변화가 생길 수 있습니다.

535
00:37:51,613 --> 00:37:55,831
하지만 여러분의 데이터셋 전체에서
무작위로 나눈다면

536
00:37:55,831 --> 00:37:59,762
그것이 바로 실제 그 문제를 완화 시킬 수 있는 방법이 될 것입니다.

537
00:38:04,297 --> 00:38:08,351
여러분이 크로스 벨리데이션 과정을
거치고 나면

538
00:38:08,351 --> 00:38:11,493
결국에는 여기 보이는것 과 같은 그래프를 
볼 수 있을 것입니다.

539
00:38:11,493 --> 00:38:17,354
여기 X 축에서는 K-NN 분류기의 K의 값을 나타냅니다.

540
00:38:17,354 --> 00:38:26,961
그리고 Y 축에서는 어떤 데이터 셋에 대해서
K 값 별 우리의 분류기의 정확도를 보여줍니다.

541
00:38:26,961 --> 00:38:31,705
이 경우에 5-fold cross vaildation 이 수행된 것을 
확인할 수 있으며

542
00:38:31,705 --> 00:38:38,346
각각의 K에 대해서, 5개의 서로 다른 데이터에 대해서 얼마나 
우리 알고리즘이 잘 동작하는지를 알려줍니다.

543
00:38:38,346 --> 00:38:41,050
그리고 다시 그 질문을 돌아가서

544
00:38:41,050 --> 00:38:44,748
테스트 셋을 가지는 것이 우리의 알고리즘에
좋은 영향을 미치는지 아닌지에 관해서라면

545
00:38:46,239 --> 00:38:50,276
K fold cross vaildation이 아마도 그 수치를
정량화 하는데 조금은 도움을 줄 것입니다.

546
00:38:50,276 --> 00:38:57,606
그리고 우리는 이 알고리즘이 다양한 validation folds에서 어떻게
성능을 내는지에 대한 분산(variance)을 확인해 볼 수 있습니다.

547
00:38:57,606 --> 00:39:04,301
분산을 보면 무엇이 최고인지 뿐만 아니라
그 성능에 대한 분포 또한 알 수 있습니다.

548
00:39:04,301 --> 00:39:06,442
그래서, 여러분이 기계학습 모델을 학습시키고 있다면

549
00:39:06,442 --> 00:39:08,151
결국 이런 식의 그래프를 그리게 될 것입니다.

550
00:39:08,151 --> 00:39:12,380
그리고 이 그래프는 정확도가 어떤지, 성능이 어떤지를
하이퍼 파라미터에 대한 함수로 나타내 줍니다.

551
00:39:12,380 --> 00:39:19,995
그리고 결국에는 벨리데이션 셋의 성능을 최고로 하는
모델 또는 하이퍼 파라미터를 선택하게 될 것입니다.

552
00:39:19,995 --> 00:39:25,528
이 예제에서는 아마 K = 7 일때가 가장 좋은
성능을 보이는 것을 알 수 있습니다.

553
00:39:29,713 --> 00:39:34,458
이미지에서는 k-NN 분류기를 실제로는 잘 쓰지 않습니다.

554
00:39:34,458 --> 00:39:38,233
왜냐하면 우리가 앞서 이야기한 문제들 때문입니다.

555
00:39:38,233 --> 00:39:41,393
첫번째 문제는 너무 느리다는 것입니다.

556
00:39:41,393 --> 00:39:44,287
우리가 원하는 것과 정 반대이며
이 내용은 앞서 이야기한 적이 있었습니다.

557
00:39:44,287 --> 00:39:54,495
또 하나의 문제는 Euclidean Distance나 L1 Distance와
같은 방법은 이미지간의 거리를 측정하기에 알맞지 않기 때문입니다.

558
00:39:54,495 --> 00:40:01,254
이러한 벡터간의 거리와 관련된 함수들은 
이미지들 간의 지각적유사성과는 잘 맞지 않습니다.

559
00:40:01,254 --> 00:40:04,076
여러분들 이미지간의 차이를 어떻게 지각하십니까?

560
00:40:04,076 --> 00:40:06,910
우리가 만든 이 예제를 보면

561
00:40:06,910 --> 00:40:08,796
왼쪽 그림에 한 여성이 있습니다.

562
00:40:08,796 --> 00:40:11,234
오른쪽에는 세 개의 왜곡된 이미지가 있습니다.

563
00:40:11,234 --> 00:40:18,416
눈과 입을 가려도 보고, 몇 픽셀식 이동도 시켜보고, 
전체 이미지에 파란색 색조도 추가시켜 보았습니다.

564
00:40:18,416 --> 00:40:22,785
그리고 박스친 이미지와 원본

565
00:40:22,785 --> 00:40:25,425
살짝 움직인 이미지와 원본, 그리고 색이 변한 이미지와 
원본의 사이의 Euclidean Distance를 비교해보면

566
00:40:25,425 --> 00:40:27,735
그들은 모두 동일한  L2 Distance를 가집니다.

567
00:40:27,735 --> 00:40:29,469
이것은 별로 좋지 않을것 같습니다.

568
00:40:29,469 --> 00:40:34,952
왜냐하면 L2 Distance가 이미지들 간의 어떤 
지각적인 Distance를 포착해 내는데

569
00:40:34,952 --> 00:40:39,119
별로 좋지 않다는 느낌을 주기 때문입니다.

570
00:40:40,642 --> 00:40:46,819
K-nn 분류기의 또 다른 문제 중 하나는 바로 우리가
"차원의 저주"라고 부르는 것입니다.

571
00:40:46,819 --> 00:40:51,279
그래서 우선 다시 K-NN 분류기도 돌아가 보자면

572
00:40:51,279 --> 00:40:57,186
K-NN이 하는 일은 각각의 트레이닝 데이터을 이용하여
각각의 공간을 나누는 일이였습니다.

573
00:40:57,186 --> 00:41:01,105
이것이 의미하는 바는 만약 우리가 k-NN 분류기가
잘 동작하기를 기대한다면

574
00:41:01,105 --> 00:41:05,646
우리는 그 공간을 상당히 조밀하게 커버할만한 
트레이닝 샘플들이 필요한 것입니다.

575
00:41:05,646 --> 00:41:15,004
그렇지 않으면 가장 가까운 이웃이 사실은 엄청 멀 수도 있고, 
그 가장 가까운 이웃은 테스트 이미지와 별로 유사하지 않을 것입니다.

576
00:41:16,738 --> 00:41:19,197
그리고 문제는 바로 실제로
공간을 조밀하게 덮어야 한다는 것은

577
00:41:19,197 --> 00:41:21,467
우리는  많은 량의 학습 데이터가 있어야 한다는 것을 의미하고

578
00:41:21,467 --> 00:41:24,666
이는 차원에 따라 기하급수 적으로 증가한다는 의미입니다.

579
00:41:24,666 --> 00:41:29,217
이것은 아주 좋지 않고, 기하급수적인 증가는 
기본적으로 항상 안좋습니다.

580
00:41:29,217 --> 00:41:35,587
여러분은 이런 고차원 공간에 존재하는 그 픽셀들의 공간을 조밀하게 
덮을 만큼의 충분한 이미지를 절대로 모으지 못할 것입니다.

581
00:41:35,587 --> 00:41:41,300
그래서 이 문제는 또 한가지의 k-NN을 사용하려 할때 여러분들이 
염두해야 할 점 이었습니다.

582
00:41:41,300 --> 00:41:45,701
그래서 요약을 해보자면, 우리는 이미지 분류 문제의
아이디어를 소개해 드리기 위해 k-NN을 이용하였습니다.

583
00:41:45,701 --> 00:41:51,445
우리는 이미지와 레이블을 가진 트레이닝 셋을 가졌고 
테스트 셋을 예측하는데 이용하였습니다.

584
00:41:51,445 --> 00:41:52,278
질문 있나요?

585
00:41:52,278 --> 00:41:54,519
[질문하는 학생]

586
00:41:54,519 --> 00:41:55,352
오 죄송합니다. 질문은

587
00:41:55,352 --> 00:41:57,271
"아까 그 그림이 어떤걸 의미하는지"

588
00:41:57,271 --> 00:41:59,168
"그림의 초록 점과 파란 점은 무엇인지" 였습니다.

589
00:41:59,168 --> 00:42:02,335
여기에는 우리가 트레이닝 샘플이 있는 것입니다.

590
00:42:03,463 --> 00:42:05,596
트레이닝 샘플을 각 점들로 표현합니다.

591
00:42:05,596 --> 00:42:11,004
그리고 각 점의 색은 트레이닝 샘플이 속한
카테고리를 나타낸다고 보시면 됩니다.

592
00:42:11,004 --> 00:42:12,629
따라서 맨 왼쪽의 1차원을 살펴보면

593
00:42:12,629 --> 00:42:17,525
이 공간을 조밀하게 덮으려면 트레이닝 샘플 4개면 충분합니다.

594
00:42:17,525 --> 00:42:19,478
하지만 2차원으로 옮겨가면

595
00:42:19,478 --> 00:42:25,529
이 공간을 다 덮으려면 16개의 트레이닝 샘플이 필요하고
1차원에서의 4배라는 것을 알 수 있습니다.

596
00:42:25,529 --> 00:42:28,767
그리고 우리가 3, 4, 5 와 같이 더
큰 차원을 고려해보면

597
00:42:28,767 --> 00:42:32,344
그 공간을 조밀하게 덮기 위해 필요한
트레이닝 샘플의 수는

598
00:42:32,344 --> 00:42:35,200
차원이 늘어남에 따라 기하급수적으로 증가하게 됩니다.

599
00:42:35,200 --> 00:42:40,501
우리가 보기엔, 예를들어 2차원에서는
우리는 어떤 커브모양이 있음을 알 수 있고

600
00:42:40,501 --> 00:42:47,641
혹은 더 높은 차원에서는 레이블들의
일종의 manifolds를 생각해 볼 수도 있을 것입니다.

601
00:42:47,641 --> 00:42:53,029
k-NN 알고리즘은 그러한 내재적인 manifolds를
가정하지 않기 때문에

602
00:42:53,029 --> 00:42:58,796
이 알고리즘이 올바르게 작동하게 하기 위한 유일한 방법은
그 공간을 조밀하게 덮을 만큼의 트레이닝 샘플을 가지는 것입니다.

603
00:43:01,741 --> 00:43:04,915
지금까지 k-NN에 대해 살펴보았으며

604
00:43:04,915 --> 00:43:11,214
여러분은 아마 첫 과제에서 이를 실제로 구현해보고
이미지들로 실험해 볼 기회가 있을 것입니다.

605
00:43:11,214 --> 00:43:16,059
그리고 남은 시간은 k-NN에 대한 질문을 좀 더 받고
다음 주제로 넘어 가도록 하겠습니다.

606
00:43:16,059 --> 00:43:16,892
질문있나요?

607
00:43:16,892 --> 00:43:21,014
[학생이 질문하고있다]

608
00:43:21,014 --> 00:43:22,034
죄송하지만 다시 말해주세요

609
00:43:22,034 --> 00:43:25,951
[학생이 질문하고있다]

610
00:43:28,437 --> 00:43:32,033
질문은 그러면 왜 저 이미지들이 같은 L2 Distance를
가지고 있는지 입니다.

611
00:43:32,033 --> 00:43:35,915
제 답변은, 제가 이 이미지들이 같은 L2 Distance를 가지도록
직접 열심히 만들었기 떄문입니다.

612
00:43:35,915 --> 00:43:38,716
[웃음]

613
00:43:38,716 --> 00:43:45,096
저는 단지 L2 Distance가 이미지간의 유사도을 측정하는데는
좋지 않다는 것에 대한 느낌을 전달하고 싶었습니다.

614
00:43:45,096 --> 00:43:50,223
실제로 이 이미지들은 저마다 모두 다릅니다.

615
00:43:52,470 --> 00:43:57,649
하지만 여러분이 K-NN을 사용한다면 이미지 간의
유사도를 특정할 수 있는 유일한 방법은

616
00:43:57,649 --> 00:44:00,236
바로 이 단일 거리 성능 척도(L1/L2 등)을 이용하는 수 밖에 없습니다.

617
00:44:00,236 --> 00:44:08,949
이 예시는 여러분들에게 Distance metric이 실제로는 
이미지간의 유사도를 잘 포착해 내지 못한다는 것을 알려줍니다.

618
00:44:08,949 --> 00:44:15,384
이 예시에 경우에 이러한 translation과 offset에도 
Distance가 일치하도록 제가 임의로 만들어낸 것입니다.

619
00:44:15,384 --> 00:44:16,217
질문 있으십니까?

620
00:44:16,217 --> 00:44:19,884
[질문하는 학생]

621
00:44:28,672 --> 00:44:36,615
질문은 바로, 이 이미지들이 같은 이미지에서 나온 것이니까
distance가 같다는 것은 사실은 좋은 것이 아니냐 하는 것입니다.

622
00:44:36,615 --> 00:44:38,024
그것 아마 이 예시 에서는 참일 수도 있습니다만

623
00:44:38,024 --> 00:44:41,810
우리는 참이 아닌 다른 예시를 만들어 볼 수도 있는데, 
서로 다른 두 개의 원본 이미지가 있고

624
00:44:41,810 --> 00:44:44,270
어떤 적절한 위치에 박스를 놓거나, 색을 더하거나 하게 되면

625
00:44:44,270 --> 00:44:48,316
결국 두 이미지의 Distance를 엄청 가깝게 할 수도 있을 것입니다.

626
00:44:48,316 --> 00:44:52,007
반대로 이 예시에서 똑같은 하나의 이미지에 
(하나의 이미지이니 Distance가 변하면 안되지만)

627
00:44:52,007 --> 00:44:57,469
임의로 움직이거나(shift) 색을 더하면(tinting) 그 Distance
는 제멋대로 변할 것입니다.

628
00:44:57,469 --> 00:45:03,172
그러니 이 방법은 여러분이 여러개의 다양한 원본 이미지를
가지고 있는 경우라면 잘못 될 수도 있는 것입니다.

629
00:45:03,172 --> 00:45:04,039
질문 있으신가요?

630
00:45:04,039 --> 00:45:07,956
[학생이 질문하고있다]

631
00:45:15,207 --> 00:45:20,664
질문은 현실에서 최고의 하이퍼 파라미터를 찾을때 까지

632
00:45:20,664 --> 00:45:24,098
데이터 셋을 다시 학습시키는 것이 흔한지 입니다.

633
00:45:24,098 --> 00:45:27,765
실제로 사람들은 가끔 그렇게 하곤 합니다.

634
00:45:28,787 --> 00:45:30,982
하지만 그때 그때 다르다고 할 수 있습니다.

635
00:45:30,982 --> 00:45:34,430
만약 여러분이 데드라인에 쫒기고 있고 
당장 모델을 사용해야 한다면

636
00:45:34,430 --> 00:45:38,176
데이터 셋 전부를 다시 학습시키는 것이 너무 오래 걸린다면

637
00:45:38,176 --> 00:45:39,875
다시 학습시키지 않을 것입니다.

638
00:45:39,875 --> 00:45:43,432
하지만 여러분이 다시 학습시킬 여유가 있다면

639
00:45:43,432 --> 00:45:50,012
그리고 남은 1%의 성능이라도 더 짜내고 싶다면 
여러분이 할 수있는 하나의 트릭이 될 수 있습니다.

640
00:45:53,288 --> 00:45:56,758
자, 지금까지는 k-NN이 기계학습 알고리즘이라는 점에서
지닌 많은 좋은 특성들에 대해 배웠습니다.

641
00:45:56,758 --> 00:46:00,490
하지만 실제로는 엄청 좋지는 않습니다.

642
00:46:00,490 --> 00:46:03,823
이미지에는 잘 사용하지 않습니다.

643
00:46:05,258 --> 00:46:08,895
다음으로 넘어가서 이야기하고 싶은건
Linear Classification 입니다.

644
00:46:08,895 --> 00:46:14,981
Linear Classification 역시 엄청 간단한 학습 알고리즘입니다.
하지만 엄청나게 중요하고

645
00:46:14,981 --> 00:46:19,845
우리가 NN과 CNN을 구축하게 해 주는 알고리즘입니다.

646
00:46:19,845 --> 00:46:23,470
사람들이 NN을 사용할때 종종 하는 비유가 있는데

647
00:46:23,470 --> 00:46:26,242
NN을 레고블럭에 비유하는 것입니다.

648
00:46:26,242 --> 00:46:30,345
여러분은 NN에 다양한 컴포넌트들을 사용할 수 있으며,
이 컴포넌트들을 한데 모아서

649
00:46:30,345 --> 00:46:36,378
CNN이라는 거대한 타워를 지을 수 있는 것입니다.

650
00:46:36,378 --> 00:46:43,215
앞으로 보게될 다양한 종류의 딥 러닝 알고리즘들의 
가장 기본이 되는 블럭중 하나가 바로 Linear classifier입니다.

651
00:46:43,215 --> 00:46:48,270
때문에 여러분이 Linear classification이 어떻게 동작하는지를
정확히 이해하는것은 정말 중요하다고 할 수 있습니다.

652
00:46:48,270 --> 00:46:52,712
왜냐면 Linear classification이 결국은 전체 NN을
이루게 될 것이기 떄문이지요.

653
00:46:52,712 --> 00:46:56,139
NN의 구조적 특성을 설명하는 또 다른 예시가 있습니다.

654
00:46:56,139 --> 00:47:00,281
우리 연구실에서 진행하는 이미지 캡셔닝 과
관련된 것이죠.

655
00:47:00,281 --> 00:47:06,226
여기에서는 입력으로 이미지를 받고, 
출력으로는 이미지를 설명하는 문장이 나옵니다.

656
00:47:06,226 --> 00:47:11,548
이를 위해 우리는 이미지를 인식하기 위해
하나의 CNN을 사용하고, -

657
00:47:11,548 --> 00:47:14,496
어떤 말을 해야할지를 알기 위해 
RNN을 사용했습니다.

658
00:47:14,496 --> 00:47:16,664
우리는 그저 두개(CNN + RNN)을 
레고 블럭처럼 붙힐 수 있고

659
00:47:16,664 --> 00:47:22,767
두 개를 한꺼번에 학습시킬 수 있습니다. 그렇게 되면 
결국 어려운 일을 해낼 수 있는 쩌는 시스템이 되는 것입니다.

660
00:47:22,767 --> 00:47:26,388
이 모델에 대에서는 앞으로 배우게 되겠지만

661
00:47:26,388 --> 00:47:36,082
여기에서 말하고 싶었던건 NN이 레고블럭과 같다는 것이고.
Linear Classifier가 그것의 기본이 블럭이 된다는 것입니다.

662
00:47:37,096 --> 00:47:41,257
하지만 2강 에서 하기엔 너무 재밌는 내용이니까
우리는 다시 CIFAR-10으로 잠시 돌아가 봐야 겠습니다.

663
00:47:41,257 --> 00:47:42,375
[웃음]

664
00:47:42,375 --> 00:47:45,641
CIFAR-10이 50,000여개의 트레이닝 샘플이 있고

665
00:47:45,641 --> 00:47:49,808
각 이미지는 32x32 픽셀을 가진 
3채널 컬러 이미지라는 것을 다시 상기시켜 봅시다.

666
00:47:52,068 --> 00:47:56,696
Linear classification에서는 K-NN과는
조금은 다른 접근 방법을 이용합니다.

667
00:47:56,696 --> 00:48:04,734
Linear classifier는 우리가 "parametric model" 
이라고 부르는 모델들의 가장 단순한 예시 입니다.

668
00:48:04,734 --> 00:48:08,685
우리의 parametric model은 두개의 요소를
가지고 있습니다.

669
00:48:08,685 --> 00:48:12,201
이미지가 들어옵니다, 
왼쪽의 고양이가 입력이죠

670
00:48:12,201 --> 00:48:17,384
그리고 우리는 이 입력 데이터를
보통  "X" 로 씁니다.

671
00:48:17,384 --> 00:48:20,220
그리고 또한 parameter 집합, 즉 weight는

672
00:48:20,220 --> 00:48:24,767
문헌에 따라 다르지만  "W"라고도 하고
세타(theta)라도고 합니다.

673
00:48:24,767 --> 00:48:30,780
이제 우리는 어떤 함수를 작성해야 하는데
이 함수는 data X와 parameter W를 가지고

674
00:48:30,780 --> 00:48:39,991
그리고는 10개의 숫자를 내뱉는 것입니다. 그 숫자는 
CIFAR-10의 각 10개의 카테고리마다의 스코어를 의미합니다.

675
00:48:39,991 --> 00:48:48,583
그 스코어를 해석해 보자면, "고양이"의 스코어가 높다는 건
입력 X가 "고양이"일 확률이 크다는 것을 의미합니다.

676
00:48:48,583 --> 00:48:49,827
질문 있으십니까?

677
00:48:49,827 --> 00:48:53,494
[질문하는 학생]

678
00:48:55,380 --> 00:48:56,717
잘못들었습니다?

679
00:48:56,717 --> 00:48:58,863
[질문하는 학생]

680
00:48:58,863 --> 00:49:01,524
질문은 "여기에서 3 뭔가요?" 입니다.
(32 x 32 x 3 의 3 이 뭔지 질문)

681
00:49:01,524 --> 00:49:06,943
예시에서의 3은 Red, Green, Blue 3 채널을 의미합니다.

682
00:49:06,943 --> 00:49:08,469
우리가 보통은 컬러 이미지를 다루기 때문이죠

683
00:49:08,469 --> 00:49:12,636
컬러 정보는 버리기 아까운 유용한 정보입니다.

684
00:49:15,323 --> 00:49:18,999
K-NN에서는 parameter가 하나도 없었죠

685
00:49:18,999 --> 00:49:22,657
우린 그저 전체 트레이닝 셋을 가지고만 있었고

686
00:49:22,657 --> 00:49:24,092
그걸 그래도 테스트에 사용했습니다.

687
00:49:24,092 --> 00:49:25,825
하지만 parametric한 접근방법 에서는

688
00:49:25,825 --> 00:49:28,196
트레이닝 데이터의 정보를 요약할 것이고

689
00:49:28,196 --> 00:49:31,105
그 요약된 정보를 parameter W안에 모으는 것입니다.

690
00:49:31,105 --> 00:49:35,371
때문에 테스트에서도 트레이닝 데이터가 더이상 필요하지 않습니다.

691
00:49:35,371 --> 00:49:37,938
테스트할때는 parameters W만 있으면 됩니다.

692
00:49:37,938 --> 00:49:44,684
이런 방법은 핸드폰과 같은 작은 디바이스에서 모델이
동작할때 아주 효율적입니다.

693
00:49:44,684 --> 00:49:50,906
그러니 어떤 함수 F의 적절한 구조를 생각해 내는것이
바로 딥 러닝이라고 할 수 있겠습니다.

694
00:49:50,906 --> 00:49:55,406
여러분은 어떻게 그 가중치와 데이터를 조합할지를 
여러가지 복잡한 방법으로 생각해 볼 수 있는데,

695
00:49:55,406 --> 00:50:01,169
그것들이 모두 서로 다른 NN 아키텍쳐를 설계하는 것입니다.

696
00:50:01,169 --> 00:50:04,132
그러나 그 두개를 결합하는 가장 쉬운 방법은 바로

697
00:50:04,132 --> 00:50:05,729
그 둘을 곱하는 것이죠

698
00:50:05,729 --> 00:50:08,833
그것이 바로 Linear classifier입니다.

699
00:50:08,833 --> 00:50:13,181
여기에서 F(x,W)는 그저 Wx 입니다.

700
00:50:13,181 --> 00:50:15,770
아마도 가장 쉬운 방정식 일 것입니다.

701
00:50:15,770 --> 00:50:18,921
이제는 이들의 차원에 대해서 파헤져 봐야 합니다.

702
00:50:18,921 --> 00:50:23,088
이미지는 32x32x3 이었죠

703
00:50:24,871 --> 00:50:31,424
이 값들을 가지고 길게 펴서
긴 열벡터로 만들어 보면

704
00:50:31,424 --> 00:50:34,715
3,072 짜리 열벡터가 됩니다.

705
00:50:34,715 --> 00:50:38,632
그리고 이 3072짜리 열벡터가 10개의 클래스 스코어가
되야 합니다.

706
00:50:39,746 --> 00:50:44,236
다시 말해, 10개의 카테고리에 대한 각 스코어를 의미하는 
10개의 숫자를 얻고 싶은 것입니다.

707
00:50:44,236 --> 00:50:49,032
이것은 행렬 W가 10 x 3072 가 되어야 한다는 것을 의미합니다.

708
00:50:49,032 --> 00:50:51,299
그래서 이 둘을 곱하게 되면

709
00:50:51,299 --> 00:50:57,086
10개의 클래스 스코어를 가진 10 x 1 짜리
하나의 열 벡터를 얻게 되는 것입니다.

710
00:50:57,086 --> 00:51:01,910
그리고 가끔은 여러분들이 "이것(바이어스)" 을 보게 될 것인데
우린 종종 바이어스 텀을 더합니다.

711
00:51:01,910 --> 00:51:06,669
바이어스 텀은 원소가 10개의 상수를 가진 벡터일 것입니다.
이들은 트레이닝 데이터와 직접적으로 연결되지 않으며

712
00:51:06,669 --> 00:51:12,235
대신에 "데이터에 독립적인" 특정 클래스에 대한 
"우선권"을 부여하는 것입니다.

713
00:51:12,235 --> 00:51:16,300
만약 여러분의 데이터셋이 불균형한 상황을 생각해 볼 수 있습니다. 
고양이 데이터가 개 데이터보다 엄청 많은 것입니다.

714
00:51:16,300 --> 00:51:23,553
그렇게 되면 고양이 클래스에 상응하는 바이어스 벡터의
요소가 더 커지게 되는 것입니다.

715
00:51:23,553 --> 00:51:27,778
이제 이 함수가 동작하는 방식을
그림으로 살펴보자면

716
00:51:28,930 --> 00:51:37,099
이 그림을 보면 왼쪽에 입력 이미지가 있습니다. 
2x2 이미지이고 전체 4개의 픽셀을 가지고 있습니다.

717
00:51:37,099 --> 00:51:42,273
그러니 이 Linear classifier가 동작하는 것을 보면
여기 2x2 이미지를 입력으로 받고

718
00:51:42,273 --> 00:51:46,577
이 이미지를 4개의 요소를 가진 열벡터로 쭉 폅니다.

719
00:51:46,577 --> 00:51:54,030
이 예제에서는 10개 클래스를 다 슬라이드에 담을 순 없으니 
고양이, 개, 배 이렇게 세가지 클래스로 제안하였습니다.

720
00:51:54,030 --> 00:51:58,197
그리고 가중치 행렬은 4x3 행렬이 될 것입니다.

721
00:51:59,890 --> 00:52:02,236
그렇게 4개의 픽셀과 3개의 클래스가 있는 것입니다.

722
00:52:02,236 --> 00:52:05,567
그리고 추가적으로 세개의 요소를 가진 
바이어스 벡터가 있습니다.

723
00:52:05,567 --> 00:52:11,125
이는 각 카테고리에 대한 데이터 독립적인 
바이어스 텀이 되는 것입니다.

724
00:52:11,125 --> 00:52:16,717
자 그럼 이제 우리는 고양이의 스코어 라는 것은 
이미지의 픽셀값들과

725
00:52:18,436 --> 00:52:22,814
그리고 가중치 행렬의의 어떤 행의 내적 에 
바이어스 텀을 더한 것임을 알 수 있습니다.

726
00:52:22,814 --> 00:52:30,157
이런 관점으로 봤을때 Linear classification이 
거의 템플릿 매칭이랑 비슷하다는 것을 알 수 있습니다.

727
00:52:30,157 --> 00:52:35,652
행렬의 각 행은 각 이미지에 대한 템플릿으로 볼 수  있고

728
00:52:35,652 --> 00:52:43,183
그리고  그 행 벡터와 이미지의 열벡터간의 내적을 하는데,

729
00:52:43,183 --> 00:52:50,458
여기에서 내적을 계산하는 것이 클래스 간 탬플릿의
유사도를 측정하는 것과 비슷하다는 것입니다.

730
00:52:50,458 --> 00:52:57,073
그 다음, 바이어스 라는 데이터 독립적인 
scailing offsets을 각 클래스에 더하는 것입니다.

731
00:53:00,837 --> 00:53:04,705
템플릿 매칭 이라는 관점으로 Linear classification 
바라 본다면

732
00:53:04,705 --> 00:53:12,799
우리가 실제로 행렬의 한 행을 뽑아내서, 그 행을 다시
이미지로 만들고 그 이미지를 시각화 시켜보면

733
00:53:12,799 --> 00:53:18,908
그 이미지는 실제로 Linear classifier가 데이터를 이해하기
위해 무슨 일을 하는지에 대한 느낌을 받을 수 있습니다.

734
00:53:18,908 --> 00:53:23,208
이 예제에서 우리는 이미지를 Linear classifier에 학습시켰습니다.

735
00:53:23,208 --> 00:53:28,974
그리고 밑에 보이는 이미지는 가중치 행렬이
실제로 어떻게 학습 되었는지를

736
00:53:28,974 --> 00:53:32,274
CIFAR-10의 각 10개의 카테고리에 해당하는 
행 벡터들을 시각화 시킨 것입니다.

737
00:53:32,274 --> 00:53:35,686
이런 식으로 우리는 실제로 이미지를 가지고
무슨 일이 일어나는 지를 알 수 있습니다.

738
00:53:35,686 --> 00:53:40,978
예를 들어 맨 왼 쪽 하단 이미지는 
비행기 클래스의 템플릿인데

739
00:53:40,978 --> 00:53:46,739
이 템플릿 전체적으로 파란 색인데, 가운데는 얼룩져 있고 
배경은 파란색 입니다.

740
00:53:46,739 --> 00:53:51,574
그리고 이를 통해 비행기 분류를 위한 Linear classifier가
어떤 푸르스름한 것들을 찾고 있는 것 같습니다.

741
00:53:51,574 --> 00:53:57,606
그런 특징은 이 분류기가 비행기를 더 잘 찾도록 해 주는 것입니다.

742
00:53:57,606 --> 00:53:59,444
자동차의 예시도 한번 보자면

743
00:53:59,444 --> 00:54:02,441
이걸 보면 어떤 중앙에는 불그스름해 보이는게 있고

744
00:54:02,441 --> 00:54:08,721
상단에는 좀 푸르스름 한 것들이 보입니다. 
아마 이건 자동차의 앞유리 같군요

745
00:54:08,721 --> 00:54:09,654
하지막 좀 이상한게 있습니다.

746
00:54:09,654 --> 00:54:13,716
실제 자동차 처럼 보이지는 않습니다.
어떤 자동차도 이렇게 생기진 않았죠

747
00:54:13,716 --> 00:54:18,317
Linear classifier의 문제 중 하나는 각 클래스에 대해서
단 하나의 템플릿만을 학습하다는 것입니다.

748
00:54:18,317 --> 00:54:24,340
그렇기 때문에 한 클래스 내에서 다양한 것들이 존재해도, 
그 다양한 것들을 모두 한번에 평균을 내버리기 때문에

749
00:54:24,340 --> 00:54:29,675
다양한 모습들이 있더라도 각 카테고리를 인식하기 
위한 템플릿은 단 하나밖에 없는 것입니다.

750
00:54:29,675 --> 00:54:33,139
이 사실은 말 을 분류하는 부분에서 잘 드러나는 대목입니다.

751
00:54:33,139 --> 00:54:37,340
보통 말이 풀밭에 서 있기 때문에, 템플릿의 바닥 쪽에도
푸르스름한 것을 볼 수 있습니다.

752
00:54:37,340 --> 00:54:43,125
그리고 유심히 보고 있으면 말의 머리가 두개인 것을 알 수 있습니다. 
각 사이드 마다 하나씩 있습니다.

753
00:54:43,125 --> 00:54:45,855
저는 머리가 두개달린 말은 본 적이 없습니다.

754
00:54:45,855 --> 00:54:52,788
하지만 Linear classifier는 카테고리 당 하나의 템플릿 밖에
허용되지 않으므로 이게 최선인 것입니다.

755
00:54:52,788 --> 00:54:59,460
하지만 NN가 좀 더 복잡한 모델로 나아 가면서, 우리는
좀 더 정확도 높은 결과를 볼 수 있을 것입니다.

756
00:54:59,460 --> 00:55:05,230
왜냐하면 카테고리 당 하나의 템플릿만 학습 할 수 있다는
제한같은 것이 없기 때문입니다.

757
00:55:09,030 --> 00:55:15,649
Linear classifier의 또 다른 관점이 하나 있는데 
이미지를 고차원 공간의 한 점으로 보는 것입니다.

758
00:55:15,649 --> 00:55:23,328
각각의 이미지을 고차원 공간의 한 점이라고 생각해 보세요

759
00:55:23,328 --> 00:55:29,305
그러면 Linear classifier는 한 카테고리를 
다른 카테고리와 구분시켜주는

760
00:55:29,305 --> 00:55:33,125
선형 결정 경계를 만들어 주는 것이라고 볼 수 있는 것입니다.

761
00:55:33,125 --> 00:55:38,897
왼쪽 상단을 보면 비행기의 예를 볼 수 있는데

762
00:55:38,897 --> 00:55:43,845
학습을 통해서 Linear classifier는 여기 보이는 파란색 선으로

763
00:55:43,845 --> 00:55:49,493
비행기 클래스와 다른 클래스를 구분하게 됩니다.

764
00:55:49,493 --> 00:55:57,318
임의의 값에서 시작한 모델이 데이터 들을 올바르게 분리하려고 
노력하는 모습을 지켜보고 있다면 아주 재밌습니다.

765
00:55:58,709 --> 00:56:04,000
하지만 여러분이 Linear classification을 고차원의  
점 이라는 관점으로 생각하면

766
00:56:04,000 --> 00:56:09,758
Linear classification이 직면할 문제에 
대해 생각해 볼 수 있습니다.

767
00:56:09,758 --> 00:56:15,232
Linear classifier이 제대로 동작하지 않을만한
예제를 만드는것은 생각보다 어렵지 않습니다.

768
00:56:15,232 --> 00:56:20,324
여기 맨 왼쪽의 예시를 보자면 우리는
두개의 카테고리를 가진 데이터셋이 있습니다.

769
00:56:20,324 --> 00:56:26,095
이게 좀 인위적일 수도 있긴 하지만 어쨌든 데이터셋은
파랑, 빨강 이라는 두개의 카테고리가 있다고 해 봅시다.

770
00:56:26,095 --> 00:56:33,122
파랑색 카테고리는 이미지 내에서 0보다 큰 홀수인 픽셀의 수 입니다.

771
00:56:33,122 --> 00:56:38,714
그리고 0보다 큰 짝수는 빨간 카테고리로 분류합니다.

772
00:56:38,714 --> 00:56:46,259
여러분이 실제로 이 평면에 위와 같은 규칙으로
직접 그려보면

773
00:56:46,259 --> 00:56:53,426
그 평면의 두개의 사분면에서 홀수개의 픽셀을 가진
파란 클래스와

774
00:56:53,426 --> 00:56:56,063
짝수개를 가진 반대의 두 사분면을 볼 수 있을 것입니다.
(예:(1.1):2(짝), (-1,1):1(홀), (-1, -1):0(짝))

775
00:56:56,063 --> 00:57:01,364
그렇게 떄문에 우리는 이 둘을 하나의 선으로는 
분류해 낼 방법이 없는 것입니다.

776
00:57:01,364 --> 00:57:05,273
이 예시는 Linear classifier로는 풀기 힘든 문제입니다.

777
00:57:05,273 --> 00:57:09,535
그리고 어쩌면 이런 예제는 전혀 인공적인 것이 아닐 수 있습니다.

778
00:57:09,535 --> 00:57:10,912
픽셀의 갯수를 세는 대신에

779
00:57:10,912 --> 00:57:16,424
영상 내 동물이나 사람의 수가 홀수인지 짝수인지를
분류하는 문제일 수도 있습니다.

780
00:57:16,424 --> 00:57:21,145
홀수와 짝수를 나누는 것 과 같은 류의
 반전성 문제(parity problem)는

781
00:57:21,145 --> 00:57:25,725
전통적으로 Linear classification으로 풀기 힘든 문제입니다.

782
00:57:28,376 --> 00:57:33,974
Linear classifier가 힘들어 하는 또하나의 문제는 
Multimodal인 경우 입니다. (맨 오른쪽)

783
00:57:33,974 --> 00:57:35,146
여기 맨 오른쪽을 보면

784
00:57:35,146 --> 00:57:41,915
블루 카테고리가 있는 세개의 섬이 있는 것을 볼 수 있습니다.

785
00:57:41,915 --> 00:57:44,791
그 외의 붉은 색은 모두 다른 카테고리에 속하는 것이죠

786
00:57:44,791 --> 00:57:47,961
이전의 예제처럼 말의 경우를 보자면

787
00:57:47,961 --> 00:57:50,959
이런 일들은 실제도 벌어질 수 있는 것입니다.

788
00:57:50,959 --> 00:57:57,268
말의 왼쪽 머리가 보이는 곳이 하나의 섬이 될 수 있고
오른쪽에 보이는 머리가 또 다른 하나의 섬이 될 수 있겠습니다.

789
00:57:57,268 --> 00:58:03,757
그러니 이 두개의 섬 사이에 하나의 선을 긋는 것은
좋은 방법이 아닌 것입니다.

790
00:58:03,757 --> 00:58:10,854
그러니 여러분이 Multimodal 데이터를 가지고 있다면 
한 클래스가 다양한 공간에서 나타날 수 있으며

791
00:58:10,854 --> 00:58:13,963
그것은 Linear classifier로는 풀 수 없는
문제가 될 수 있습니다.

792
00:58:13,963 --> 00:58:18,575
Linear classifier에는 문제가 좀 있긴 하지만 아주 심플하고

793
00:58:18,575 --> 00:58:22,259
이해하기 쉽고 해석하기 쉬운 알고리즘입니다.

794
00:58:22,259 --> 00:58:27,245
아마 여러분은 첫 과제로 이걸 구현하게 될 것입니다.

795
00:58:28,852 --> 00:58:34,402
정리해 보자면, 우리는 지금까지 Linear classifier
의 함수적 형태에 대해 알아 보았습니다.

796
00:58:34,402 --> 00:58:39,185
그리고 행렬x벡터곱 이라는 이런 "함수적 형태"가

797
00:58:39,185 --> 00:58:44,922
템플릿 매팅 이라는 아이디어와 관련이 있으며, 따라서  데이터의 
각 카테고리에 대한 하나의 템플릿을 학습한다는 것을 배웠습니다.

798
00:58:44,922 --> 00:58:55,738
그러므로 어떤 학습된 행렬(W)를 얻고 나면 다른 어떤
새로운 학습 데이터에도 스코어를 매길 수 있게 됩니다.

799
00:58:55,738 --> 00:59:01,951
여러분에게 한가지 언급하지 않은 것이 있다면 
여러분의 데이터셋에 맞는 적절한 W를 구하는 방법입니다.

800
00:59:01,951 --> 00:59:03,908
우리는 지금까지 함수적인 형태에 대에서만 말해 왔고

801
00:59:03,908 --> 00:59:06,907
그것이 어떻게 작동하는지에 대해서만 알아봤습니다.

802
00:59:06,907 --> 00:59:11,086
이 슬라이드에 있는것이 우리가 다음 시간에 다룰 내용입니다.

803
00:59:11,086 --> 00:59:16,581
다음 강의에서는 올바른 W를 고르는 전략과
알고리즘에 대해서 이야기해 보도록 하겠습니다.

804
00:59:16,581 --> 00:59:21,322
그리고 그런 문제들은 결국 비용 함수와 최적화 
그리고 결국에는 ConvNet에 대한 질문으로 이어질 것입니다.

805
00:59:21,322 --> 00:59:25,044
그것 아마도 다음주 강의를 위한
프리뷰가 될 것입니다.

806
00:59:25,044 --> 00:59:27,044
오늘은 여기까지 하겠습니다.

